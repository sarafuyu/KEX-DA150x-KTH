{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNIZ0oiqVv8q"
   },
   "source": [
    "# Data Processing\n",
    "\n",
    "Data visualization, cleaning, division, and normalization.\n",
    "\n",
    "* Execute small adjustments/renaming of columns\n",
    "* Disease parameter: DMD/Cnt -> 1/0\n",
    "* Remove rows if:\n",
    "  * Sample.ID's value is \"BLANK\", \"POOL 1\" or \"POOL 2\"\n",
    "  * Disease or Sample.ID value for row is missing  \n",
    "* If there are multiple rows with same Sample.ID, drop the duplicate rows with fewer value entires\n",
    "  * Might need to evalueate manually or reevaluate the heuristiics (which proteins to prioritize over others)\n",
    "* Remove columns of antibody consentrations if there are no data entries\n",
    "\n",
    "* TODO: debugg, continue with later points\n",
    "* Potentionally normalize intensities: [-1, 1] or [0, 1]\n",
    "* Create new column for LoA based on FT1-5 \n",
    "\n",
    "* Flytta om ordningen på kolumnerna så att varje rad blir en vektor på formen <<METADATA>,<Y>,<X>> där <X> är [LoA], <Y> är intensiteterna (och eventuellt ålder senare) och <METADATA> är allt annat.\n",
    "\n",
    "* Run a SVM with our input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviroment to read and process DMD data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeiNQxvnXphM"
   },
   "source": [
    "Imports used for data processing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1710344580569,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "7Y_AEHs1hXrm",
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.477250Z",
     "start_time": "2024-04-09T11:06:45.878635Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhloDaQfbCZK"
   },
   "source": [
    "Load CSV file through pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "lUDzHuv3Xxcm",
    "outputId": "c9cdef14-583c-495f-e44c-a0ea72be5bdb",
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.615678Z",
     "start_time": "2024-04-09T11:06:46.478256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   ID Sample.ID Participant.ID dataset Disease  patregag TREAT  FT1  FT2  FT3  \\\n0   1       S87             P3    DNHS     DMD     11.61   NaN  0.0  0.0  NaN   \n1   2       S10             P3    DNHS     DMD     12.62   NaN  NaN  NaN  NaN   \n2   3       S19             P3    DNHS     DMD     13.62   NaN  NaN  NaN  NaN   \n3   4      S137             P4    DNHS     DMD     11.43   NaN  NaN  NaN  NaN   \n4   5      S182             P4    DNHS     DMD     13.25   NaN  NaN  NaN  NaN   \n\n   ...  HPA049320_SBA4_rep1  HPA051620_SBA4_rep1  HPA054862_SBA4_rep1  \\\n0  ...            12.476497            12.666707            12.331400   \n1  ...            12.494297            12.564169            12.354718   \n2  ...            12.554581            12.707240            12.460004   \n3  ...            12.455811            12.505603            12.416459   \n4  ...            12.523768            12.598164            12.369592   \n\n  HPA003901_SBA4_rep1  HPA035863_SBA4_rep1  HPA040052_SBA4_rep1  \\\n0           12.410101            12.504796            12.580695   \n1           12.581718            12.441237            12.583769   \n2           12.610387            12.504661            12.556319   \n3           12.510771            12.472934            12.556096   \n4           12.605211            12.523768            12.503911   \n\n   HPA041542_SBA4_rep1  HPA044582_SBA4_rep1  HPA045702_SBA4_rep1  \\\n0            12.574592            12.797013            12.492433   \n1            12.579893            12.660894            12.450384   \n2            12.679701            12.824755            12.517335   \n3            12.473760            12.744020            12.511776   \n4            12.557672            12.926602            12.518327   \n\n   HPA048982_SBA4_rep1  \n0            12.622226  \n1            12.704464  \n2            12.836970  \n3            12.666065  \n4            12.668579  \n\n[5 rows x 1039 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Sample.ID</th>\n      <th>Participant.ID</th>\n      <th>dataset</th>\n      <th>Disease</th>\n      <th>patregag</th>\n      <th>TREAT</th>\n      <th>FT1</th>\n      <th>FT2</th>\n      <th>FT3</th>\n      <th>...</th>\n      <th>HPA049320_SBA4_rep1</th>\n      <th>HPA051620_SBA4_rep1</th>\n      <th>HPA054862_SBA4_rep1</th>\n      <th>HPA003901_SBA4_rep1</th>\n      <th>HPA035863_SBA4_rep1</th>\n      <th>HPA040052_SBA4_rep1</th>\n      <th>HPA041542_SBA4_rep1</th>\n      <th>HPA044582_SBA4_rep1</th>\n      <th>HPA045702_SBA4_rep1</th>\n      <th>HPA048982_SBA4_rep1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>S87</td>\n      <td>P3</td>\n      <td>DNHS</td>\n      <td>DMD</td>\n      <td>11.61</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.476497</td>\n      <td>12.666707</td>\n      <td>12.331400</td>\n      <td>12.410101</td>\n      <td>12.504796</td>\n      <td>12.580695</td>\n      <td>12.574592</td>\n      <td>12.797013</td>\n      <td>12.492433</td>\n      <td>12.622226</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>S10</td>\n      <td>P3</td>\n      <td>DNHS</td>\n      <td>DMD</td>\n      <td>12.62</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.494297</td>\n      <td>12.564169</td>\n      <td>12.354718</td>\n      <td>12.581718</td>\n      <td>12.441237</td>\n      <td>12.583769</td>\n      <td>12.579893</td>\n      <td>12.660894</td>\n      <td>12.450384</td>\n      <td>12.704464</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>S19</td>\n      <td>P3</td>\n      <td>DNHS</td>\n      <td>DMD</td>\n      <td>13.62</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.554581</td>\n      <td>12.707240</td>\n      <td>12.460004</td>\n      <td>12.610387</td>\n      <td>12.504661</td>\n      <td>12.556319</td>\n      <td>12.679701</td>\n      <td>12.824755</td>\n      <td>12.517335</td>\n      <td>12.836970</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>S137</td>\n      <td>P4</td>\n      <td>DNHS</td>\n      <td>DMD</td>\n      <td>11.43</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.455811</td>\n      <td>12.505603</td>\n      <td>12.416459</td>\n      <td>12.510771</td>\n      <td>12.472934</td>\n      <td>12.556096</td>\n      <td>12.473760</td>\n      <td>12.744020</td>\n      <td>12.511776</td>\n      <td>12.666065</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>S182</td>\n      <td>P4</td>\n      <td>DNHS</td>\n      <td>DMD</td>\n      <td>13.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.523768</td>\n      <td>12.598164</td>\n      <td>12.369592</td>\n      <td>12.605211</td>\n      <td>12.523768</td>\n      <td>12.503911</td>\n      <td>12.557672</td>\n      <td>12.926602</td>\n      <td>12.518327</td>\n      <td>12.668579</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1039 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('normalised_data_all_w_clinical_kex_20240321.csv')\n",
    "dataset.head() # Pre-view first five rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mU1AUw0annb"
   },
   "source": [
    "## First Data Visualization & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.648476Z",
     "start_time": "2024-04-09T11:06:46.616688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Sample_ID', 'Participant_ID', 'Dataset', 'Disease', 'Age',\n",
      "       'TREAT', 'FT1', 'FT2', 'FT3',\n",
      "       ...\n",
      "       'HPA049320_SBA4_rep1', 'HPA051620_SBA4_rep1', 'HPA054862_SBA4_rep1',\n",
      "       'HPA003901_SBA4_rep1', 'HPA035863_SBA4_rep1', 'HPA040052_SBA4_rep1',\n",
      "       'HPA041542_SBA4_rep1', 'HPA044582_SBA4_rep1', 'HPA045702_SBA4_rep1',\n",
      "       'HPA048982_SBA4_rep1'],\n",
      "      dtype='object', length=1039)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\AppData\\Local\\Temp\\ipykernel_392584\\3529643249.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset['Disease'] = dataset['Disease'].replace(token_to_val)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   ID Sample_ID Participant_ID Dataset  Disease    Age TREAT  FT1  FT2  FT3  \\\n0   1       S87             P3    DNHS      1.0  11.61   NaN  0.0  0.0  NaN   \n1   2       S10             P3    DNHS      1.0  12.62   NaN  NaN  NaN  NaN   \n2   3       S19             P3    DNHS      1.0  13.62   NaN  NaN  NaN  NaN   \n3   4      S137             P4    DNHS      1.0  11.43   NaN  NaN  NaN  NaN   \n4   5      S182             P4    DNHS      1.0  13.25   NaN  NaN  NaN  NaN   \n\n   ...  HPA049320_SBA4_rep1  HPA051620_SBA4_rep1  HPA054862_SBA4_rep1  \\\n0  ...            12.476497            12.666707            12.331400   \n1  ...            12.494297            12.564169            12.354718   \n2  ...            12.554581            12.707240            12.460004   \n3  ...            12.455811            12.505603            12.416459   \n4  ...            12.523768            12.598164            12.369592   \n\n  HPA003901_SBA4_rep1  HPA035863_SBA4_rep1  HPA040052_SBA4_rep1  \\\n0           12.410101            12.504796            12.580695   \n1           12.581718            12.441237            12.583769   \n2           12.610387            12.504661            12.556319   \n3           12.510771            12.472934            12.556096   \n4           12.605211            12.523768            12.503911   \n\n   HPA041542_SBA4_rep1  HPA044582_SBA4_rep1  HPA045702_SBA4_rep1  \\\n0            12.574592            12.797013            12.492433   \n1            12.579893            12.660894            12.450384   \n2            12.679701            12.824755            12.517335   \n3            12.473760            12.744020            12.511776   \n4            12.557672            12.926602            12.518327   \n\n   HPA048982_SBA4_rep1  \n0            12.622226  \n1            12.704464  \n2            12.836970  \n3            12.666065  \n4            12.668579  \n\n[5 rows x 1039 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Sample_ID</th>\n      <th>Participant_ID</th>\n      <th>Dataset</th>\n      <th>Disease</th>\n      <th>Age</th>\n      <th>TREAT</th>\n      <th>FT1</th>\n      <th>FT2</th>\n      <th>FT3</th>\n      <th>...</th>\n      <th>HPA049320_SBA4_rep1</th>\n      <th>HPA051620_SBA4_rep1</th>\n      <th>HPA054862_SBA4_rep1</th>\n      <th>HPA003901_SBA4_rep1</th>\n      <th>HPA035863_SBA4_rep1</th>\n      <th>HPA040052_SBA4_rep1</th>\n      <th>HPA041542_SBA4_rep1</th>\n      <th>HPA044582_SBA4_rep1</th>\n      <th>HPA045702_SBA4_rep1</th>\n      <th>HPA048982_SBA4_rep1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>S87</td>\n      <td>P3</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>11.61</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.476497</td>\n      <td>12.666707</td>\n      <td>12.331400</td>\n      <td>12.410101</td>\n      <td>12.504796</td>\n      <td>12.580695</td>\n      <td>12.574592</td>\n      <td>12.797013</td>\n      <td>12.492433</td>\n      <td>12.622226</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>S10</td>\n      <td>P3</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>12.62</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.494297</td>\n      <td>12.564169</td>\n      <td>12.354718</td>\n      <td>12.581718</td>\n      <td>12.441237</td>\n      <td>12.583769</td>\n      <td>12.579893</td>\n      <td>12.660894</td>\n      <td>12.450384</td>\n      <td>12.704464</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>S19</td>\n      <td>P3</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>13.62</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.554581</td>\n      <td>12.707240</td>\n      <td>12.460004</td>\n      <td>12.610387</td>\n      <td>12.504661</td>\n      <td>12.556319</td>\n      <td>12.679701</td>\n      <td>12.824755</td>\n      <td>12.517335</td>\n      <td>12.836970</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>S137</td>\n      <td>P4</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>11.43</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.455811</td>\n      <td>12.505603</td>\n      <td>12.416459</td>\n      <td>12.510771</td>\n      <td>12.472934</td>\n      <td>12.556096</td>\n      <td>12.473760</td>\n      <td>12.744020</td>\n      <td>12.511776</td>\n      <td>12.666065</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>S182</td>\n      <td>P4</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>13.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.523768</td>\n      <td>12.598164</td>\n      <td>12.369592</td>\n      <td>12.605211</td>\n      <td>12.523768</td>\n      <td>12.503911</td>\n      <td>12.557672</td>\n      <td>12.926602</td>\n      <td>12.518327</td>\n      <td>12.668579</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1039 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Dictionary for value conversion\n",
    "token_to_val = {\n",
    "    \"DMD\": 1,\n",
    "    \"Cnt\": 0\n",
    "}\n",
    "# Rename columns\n",
    "dataset.rename(columns={dataset.columns[0]: 'ID'}, inplace=True)\n",
    "dataset.rename(columns={'Sample.ID': 'Sample_ID'}, inplace=True)\n",
    "dataset.rename(columns={'Participant.ID': 'Participant_ID'}, inplace=True)\n",
    "dataset.rename(columns={'dataset': 'Dataset'}, inplace=True)\n",
    "dataset.rename(columns={'patregag': 'Age'}, inplace=True)\n",
    "\n",
    "# Replace the string values in the column using the mapping in token_to_val\n",
    "dataset['Disease'] = dataset['Disease'].replace(token_to_val)\n",
    "\n",
    "# Verify the change\n",
    "print(dataset.columns)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.659262Z",
     "start_time": "2024-04-09T11:06:46.650485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         FT1       FT2       FT3    FT4   FT5\n",
      "0   0.000000  0.000000       NaN    NaN   NaN\n",
      "1        NaN       NaN       NaN    NaN   NaN\n",
      "2        NaN       NaN       NaN    NaN   NaN\n",
      "3        NaN       NaN       NaN    NaN   NaN\n",
      "4        NaN       NaN       NaN    NaN   NaN\n",
      "5   2.538071  0.628931  0.367647  488.7  32.0\n",
      "6   2.531646  0.492611  0.275482  475.0  29.0\n",
      "7        NaN       NaN       NaN    NaN   NaN\n",
      "8   2.237136  0.346021  0.176991  449.0  31.0\n",
      "9        NaN       NaN       NaN    NaN  34.0\n",
      "10       NaN       NaN       NaN    NaN  34.0\n",
      "11       NaN       NaN       NaN    NaN  34.0\n",
      "12       NaN       NaN       NaN    NaN  34.0\n",
      "13       NaN       NaN       NaN    NaN  34.0\n",
      "14       NaN       NaN       NaN    NaN  34.0\n"
     ]
    }
   ],
   "source": [
    "# Give control group (non DMD) default value of 34 (top score) on FT5\n",
    "in_control = dataset['Disease']  == 0.0\n",
    "control_index = in_control[in_control == True].index\n",
    "dataset.loc[control_index, 'FT5'] = 34\n",
    "\n",
    "# Verify the change\n",
    "print(dataset.iloc[:15, 7:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Based Data Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.666097Z",
     "start_time": "2024-04-09T11:06:46.660268Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_column_value_percentage(df, start_column=1): # TODO: add end_column param\n",
    "    \"\"\"\n",
    "    Calculates the percentage of actual (non-NA) data points for each column in a pandas DataFrame\n",
    "    within a specified column interval.\n",
    "\n",
    "    :param df: A pandas DataFrame with potential NA values.\n",
    "    :param start_column: The starting column index for the interval (1-based index).\n",
    "    :param end_column: The ending column index for the interval. If None, calculates up to \n",
    "    the last column. \n",
    "    :return: A pandas Series with the percentage of non-NA values for each column in the interval.\n",
    "    \"\"\"\n",
    "    # Adjust for 0-based indexing\n",
    "    start_index = max(0, start_column - 1)\n",
    "\n",
    "    # Select only the columns within the specified interval\n",
    "    interval_df = df.iloc[:, start_index:]\n",
    "\n",
    "    # Calculate the total number of non-NA values for each column\n",
    "    value_counts = interval_df.count()\n",
    "\n",
    "    # Calculate the total number of rows (to handle potential NA rows)\n",
    "    total_rows = len(df)\n",
    "\n",
    "    # Calculate the percentage of non-NA values for each column\n",
    "    val_percentage = (value_counts / total_rows) * 100\n",
    "\n",
    "    return val_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.678806Z",
     "start_time": "2024-04-09T11:06:46.667101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column HPA003948_SBA1_rep1 has 0.00% non-NA values\n",
      "Column HPA059806_SBA1_rep1 has 11.20% non-NA values\n",
      "Column HPA055893_SBA2_rep1 has 41.15% non-NA values\n",
      "Column HPA035933_SBA2_rep1 has 33.07% non-NA values\n",
      "Column HPA009426_SBA2_rep1 has 32.29% non-NA values\n",
      "Column HPA057437_SBA3_rep1 has 0.00% non-NA values\n",
      "Column HPA003909_SBA3_rep1 has 15.89% non-NA values\n",
      "Column HPA015774_SBA3_rep1 has 42.45% non-NA values\n",
      "Column HPA003223_SBA3_rep1 has 6.77% non-NA values\n",
      "Column HPA003948_SBA3_rep1 has 0.00% non-NA values\n",
      "Column Empty_SBA3_rep1 has 8.85% non-NA values\n",
      "Column HPA040591_SBA3_rep1 has 30.99% non-NA values\n",
      "Column HPA034960_SBA3_rep1 has 0.00% non-NA values\n",
      "Column HPA021513_SBA3_rep1 has 43.75% non-NA values\n",
      "Column HPA058513_SBA3_rep1 has 0.00% non-NA values\n",
      "Column HPA036287_SBA3_rep1 has 11.46% non-NA values\n",
      "Column HPA073315_SBA3_rep1 has 13.54% non-NA values\n",
      "Column HPA041863_SBA3_rep1 has 34.38% non-NA values\n",
      "Column HPA004712_SBA3_rep1 has 34.64% non-NA values\n",
      "Column HPA074922_SBA3_rep1 has 0.00% non-NA values\n",
      "Column HPA000837_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA001482_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA000293_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA007982_SBA4_rep1 has 31.51% non-NA values\n",
      "Column HPA028190_SBA4_rep1 has 14.32% non-NA values\n",
      "Column HPA031466_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA040972_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA001526_SBA4_rep1 has 8.85% non-NA values\n",
      "Column HPA002021_SBA4_rep1 has 45.57% non-NA values\n",
      "Column HPA010558_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA013390_SBA4_rep1 has 7.03% non-NA values\n",
      "Column HPA020610_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA028657_SBA4_rep1 has 34.64% non-NA values\n",
      "Column HPA030651_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA000226_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA007316_SBA4_rep1 has 10.42% non-NA values\n",
      "Column HPA008128_SBA4_rep1 has 7.55% non-NA values\n",
      "Column HPA064736_SBA4_rep1 has 49.74% non-NA values\n",
      "Column HPA041991_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA000564_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA007427_SBA4_rep1 has 22.14% non-NA values\n",
      "Column HPA035222_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA041943_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA001373_SBA4_rep1 has 31.51% non-NA values\n",
      "Column HPA001833_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA003927_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA006666_SBA4_rep1 has 6.51% non-NA values\n",
      "Column HPA008880_SBA4_rep1 has 26.30% non-NA values\n",
      "Column HPA015109_SBA4_rep1 has 7.03% non-NA values\n",
      "Column HPA027526_SBA4_rep1 has 38.02% non-NA values\n",
      "Column HPA035029_SBA4_rep1 has 45.57% non-NA values\n",
      "Column HPA003157_SBA4_rep1 has 13.80% non-NA values\n",
      "Column HPA011918_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA023314_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA015236_SBA4_rep1 has 21.61% non-NA values\n",
      "Column HPA031335_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA031717_SBA4_rep1 has 0.00% non-NA values\n",
      "Column HPA026430_SBA4_rep1 has 7.81% non-NA values\n",
      "We have 58 proteins with less than 50% datapoints\n"
     ]
    }
   ],
   "source": [
    "# Calculate column statistics for low content columns\n",
    "value_percentage = calculate_column_value_percentage(dataset, 15)\n",
    "limit = 50\n",
    "low_percentage_columns = value_percentage[value_percentage < limit]\n",
    "\n",
    "# Visualize status\n",
    "num = 0\n",
    "for column, percentage in low_percentage_columns.items():\n",
    "    print(f\"Column {column} has {percentage:.2f}% non-NA values\")\n",
    "    num += 1\n",
    "\n",
    "print(f\"We have {num} proteins with less than {limit}% datapoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.686507Z",
     "start_time": "2024-04-09T11:06:46.679813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop: Index(['HPA003948_SBA1_rep1', 'HPA059806_SBA1_rep1', 'HPA055893_SBA2_rep1',\n",
      "       'HPA035933_SBA2_rep1', 'HPA009426_SBA2_rep1', 'HPA057437_SBA3_rep1',\n",
      "       'HPA003909_SBA3_rep1', 'HPA015774_SBA3_rep1', 'HPA003223_SBA3_rep1',\n",
      "       'HPA003948_SBA3_rep1', 'Empty_SBA3_rep1', 'HPA040591_SBA3_rep1',\n",
      "       'HPA034960_SBA3_rep1', 'HPA021513_SBA3_rep1', 'HPA058513_SBA3_rep1',\n",
      "       'HPA036287_SBA3_rep1', 'HPA073315_SBA3_rep1', 'HPA041863_SBA3_rep1',\n",
      "       'HPA004712_SBA3_rep1', 'HPA074922_SBA3_rep1', 'HPA000837_SBA4_rep1',\n",
      "       'HPA001482_SBA4_rep1', 'HPA000293_SBA4_rep1', 'HPA007982_SBA4_rep1',\n",
      "       'HPA028190_SBA4_rep1', 'HPA031466_SBA4_rep1', 'HPA040972_SBA4_rep1',\n",
      "       'HPA001526_SBA4_rep1', 'HPA002021_SBA4_rep1', 'HPA010558_SBA4_rep1',\n",
      "       'HPA013390_SBA4_rep1', 'HPA020610_SBA4_rep1', 'HPA028657_SBA4_rep1',\n",
      "       'HPA030651_SBA4_rep1', 'HPA000226_SBA4_rep1', 'HPA007316_SBA4_rep1',\n",
      "       'HPA008128_SBA4_rep1', 'HPA064736_SBA4_rep1', 'HPA041991_SBA4_rep1',\n",
      "       'HPA000564_SBA4_rep1', 'HPA007427_SBA4_rep1', 'HPA035222_SBA4_rep1',\n",
      "       'HPA041943_SBA4_rep1', 'HPA001373_SBA4_rep1', 'HPA001833_SBA4_rep1',\n",
      "       'HPA003927_SBA4_rep1', 'HPA006666_SBA4_rep1', 'HPA008880_SBA4_rep1',\n",
      "       'HPA015109_SBA4_rep1', 'HPA027526_SBA4_rep1', 'HPA035029_SBA4_rep1',\n",
      "       'HPA003157_SBA4_rep1', 'HPA011918_SBA4_rep1', 'HPA023314_SBA4_rep1',\n",
      "       'HPA015236_SBA4_rep1', 'HPA031335_SBA4_rep1', 'HPA031717_SBA4_rep1',\n",
      "       'HPA026430_SBA4_rep1'],\n",
      "      dtype='object')\n",
      "Before drop: (384, 1039)\n",
      "After drop: (384, 981)\n"
     ]
    }
   ],
   "source": [
    "# Remove empty columns\n",
    "columns_to_drop = low_percentage_columns.index\n",
    "print(\"Columns to drop:\", columns_to_drop)\n",
    "\n",
    "# Check changes\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "dataset.drop(labels=columns_to_drop, axis=\"columns\", inplace=True)\n",
    "print(\"After drop:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.696561Z",
     "start_time": "2024-04-09T11:06:46.687515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: (384, 981)\n",
      "After drop: (384, 976)\n"
     ]
    }
   ],
   "source": [
    "# Remove abundant data and calibration columns\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "dataset.drop(labels=['TREAT', 'Plate', 'Location', 'Empty_SBA1_rep1', 'Rabbit.IgG_SBA1_rep1'], axis='columns', inplace=True)\n",
    "print(\"After drop:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row Based Data Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.702638Z",
     "start_time": "2024-04-09T11:06:46.697568Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_wrong_value_rows(df, column_name, wrong_val):\n",
    "    \"\"\"\n",
    "    Removes rows from the DataFrame where the specified column has the specified wrong value.\n",
    "\n",
    "    :param df: A pandas DataFrame from which rows will be removed.\n",
    "    :param column_name: The name of the column to check for the wrong value.\n",
    "    :param wrong_val: The value considered wrong in the specified column.\n",
    "    :return: A pandas DataFrame with rows containing the wrong value in the specified column removed.\n",
    "    \"\"\"\n",
    "    if isinstance(wrong_val, str):\n",
    "        wrong_val = list([wrong_val])\n",
    "        \n",
    "    for val in wrong_val:\n",
    "        # Find indices of rows with the wrong value\n",
    "        incorrect = dataset[column_name] == val\n",
    "        idxs_to_drop = incorrect[incorrect == True].index\n",
    "        # Drop these rows\n",
    "        df.drop(idxs_to_drop, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.722339Z",
     "start_time": "2024-04-09T11:06:46.705648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: (384, 976)\n",
      "After drop: (372, 976)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with invalid sample data\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "dataset = remove_wrong_value_rows(dataset, 'Sample_ID', ['BLANK', 'POOL 1', 'POOL 2'])\n",
    "print(\"After drop:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.732628Z",
     "start_time": "2024-04-09T11:06:46.723349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: (372, 976)\n",
      "After drop: (357, 976)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN in the row's key values\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "dataset.dropna(subset=['Sample_ID','Disease'], inplace=True)\n",
    "print(\"After drop:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle sample duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.738776Z",
     "start_time": "2024-04-09T11:06:46.733636Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_duplicate_indices(df, cols):\n",
    "    \"\"\"\n",
    "    Find indices of rows with the wrong value in the specified column.\n",
    "    \"\"\"\n",
    "    duplicate = df.duplicated(subset=cols, keep=False)\n",
    "    duplicate_idxs = duplicate[duplicate == True].index\n",
    "    return duplicate_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.747653Z",
     "start_time": "2024-04-09T11:06:46.739782Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_row_value_percentage(df, start_column=0):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of actual (non-NA) data points for each row in a pandas DataFrame.\n",
    "\n",
    "    :param start_column: \n",
    "    :param df: A pandas DataFrame with potential NA values.\n",
    "    :return: A pandas Series with the percentage of non-NA values for each row.\n",
    "    \"\"\"\n",
    "    # Adjust for 0-based indexing\n",
    "    start_index = max(0, start_column - 1)\n",
    "\n",
    "    # Select only the columns within the specified interval\n",
    "    interval_df = df.iloc[:, start_index:]\n",
    "\n",
    "    # Calculate the number of non-NA values per row\n",
    "    value_counts_per_row = df.notna().sum(axis=1)\n",
    "\n",
    "    # Calculate the total number of columns (to handle potential NA values)\n",
    "    total_columns = interval_df.shape[1]\n",
    "\n",
    "    # Calculate the percentage of non-NA values for each row\n",
    "    value_percentage_per_row = (value_counts_per_row / total_columns) * 100\n",
    "\n",
    "    return value_percentage_per_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.757889Z",
     "start_time": "2024-04-09T11:06:46.748662Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_duplicate_rows(df, duplicate_idxs, row_val_perc):\n",
    "\n",
    "    for i in duplicate_idxs:\n",
    "        # For each duplicate find the duplicate sample.ID value using the index\n",
    "        sample_ID = df.iloc[i]['Sample_ID']\n",
    "\n",
    "        # Find all row indices of occurrences of the value\n",
    "        duplicate_sample_ID_indices = df.index[df['Sample_ID'] == sample_ID]\n",
    "\n",
    "        # Find which of these rows have the highest percentage in row_val_percentages\n",
    "        best_index = -1\n",
    "        best_val = -1\n",
    "        for duplicate_idx in duplicate_sample_ID_indices:\n",
    "            val = row_val_perc.loc[duplicate_idx]\n",
    "\n",
    "            if val > best_val:\n",
    "                best_val = val\n",
    "                best_index = duplicate_idx\n",
    "\n",
    "        # Remove best from list of duplicates\n",
    "        duplicate_sample_ID_indices = duplicate_sample_ID_indices.drop(best_index)\n",
    "\n",
    "        # Drop the rest of the duplicates\n",
    "        df.drop(index=duplicate_sample_ID_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.851147Z",
     "start_time": "2024-04-09T11:06:46.759903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: (357, 976)\n",
      "After drop: (342, 976)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows for same Sample_ID\n",
    "duplicate_indexes = get_duplicate_indices(dataset, 'Sample_ID')\n",
    "row_val_percentages = calculate_row_value_percentage(dataset, start_column=15)\n",
    "\n",
    "# Check changes\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "remove_duplicate_rows(dataset, duplicate_indexes, row_val_percentages)\n",
    "print(\"After drop:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Row handling based on FT5 (Should consider data generation based on age/other tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:46.878574Z",
     "start_time": "2024-04-09T11:06:46.852156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: (342, 976)\n",
      "After drop: (301, 976)\n"
     ]
    },
    {
     "data": {
      "text/plain": "    ID Sample_ID Participant_ID Dataset  Disease    Age       FT1       FT2  \\\n5    6      S237             P5    DNHS      1.0  11.72  2.538071  0.628931   \n6    7      S220             P5    DNHS      1.0  13.41  2.531646  0.492611   \n8    9       S91             P6    DNHS      1.0  11.76  2.237136  0.346021   \n9   10       S49           P134    DNHS      0.0    NaN       NaN       NaN   \n16  17       S79           P134    DNHS      0.0    NaN       NaN       NaN   \n18  19       S70           P135    DNHS      0.0    NaN       NaN       NaN   \n21  22        S2           P135    DNHS      0.0    NaN       NaN       NaN   \n26  27       S83           P136    DNHS      0.0    NaN       NaN       NaN   \n27  28       S41           P136    DNHS      0.0    NaN       NaN       NaN   \n31  32      S276             P7    DNHS      1.0  10.90  1.461988  0.155763   \n32  33      S302             P7    DNHS      1.0  11.94  0.995025  0.117233   \n33  34      S351             P7    DNHS      1.0  12.67  0.923361  0.092764   \n35  36      S348             P9    DNHS      1.0  11.12       NaN  0.196078   \n36  37      S286             P9    DNHS      1.0  12.03  1.020408  0.112360   \n38  39      S273            P10    DNHS      1.0  11.58  0.869565       NaN   \n\n         FT3    FT4  ...  HPA049320_SBA4_rep1  HPA051620_SBA4_rep1  \\\n5   0.367647  488.7  ...            12.543301            12.608368   \n6   0.275482  475.0  ...            12.390816            12.571472   \n8   0.176991  449.0  ...            12.464468            12.599863   \n9        NaN    NaN  ...            12.560804            12.531565   \n16       NaN    NaN  ...            12.583934            12.599499   \n18       NaN    NaN  ...            12.456166            12.597872   \n21       NaN    NaN  ...            12.481201            12.621694   \n26       NaN    NaN  ...            12.403677            12.545281   \n27       NaN    NaN  ...            12.391321            12.450349   \n31  0.114155  317.0  ...            12.476450            12.425208   \n32  0.093284  150.0  ...                  NaN                  NaN   \n33  0.070972    NaN  ...            12.476410            12.483707   \n35       NaN    NaN  ...            12.428524            12.626223   \n36       NaN   75.0  ...            12.380450            12.483917   \n38  0.000000  209.0  ...            12.488839            12.597753   \n\n    HPA054862_SBA4_rep1  HPA003901_SBA4_rep1  HPA035863_SBA4_rep1  \\\n5                   NaN                  NaN            12.598509   \n6             12.389882            12.490296            12.522449   \n8             12.459217            12.509688            12.482434   \n9             12.490397            12.419143            12.585085   \n16            12.527210            12.636333            12.440678   \n18            12.496037            12.652614            12.457952   \n21            12.415145            12.616261            12.450933   \n26                  NaN            12.439043            12.489224   \n27            12.378164            12.358069            12.510605   \n31                  NaN            12.397139            12.523445   \n32                  NaN                  NaN            12.397159   \n33                  NaN            12.294553            12.562372   \n35                  NaN            12.414213            12.507686   \n36                  NaN            12.590108            12.615858   \n38            12.562960            12.415403            12.642297   \n\n    HPA040052_SBA4_rep1  HPA041542_SBA4_rep1  HPA044582_SBA4_rep1  \\\n5             12.452527            12.495444            12.800951   \n6             12.519723            12.413517            12.917533   \n8             12.507582            12.593243            12.733109   \n9             12.509866            12.386933            12.820761   \n16            12.555278            12.617759            12.909895   \n18            12.487103            12.521334            12.823034   \n21            12.536485            12.559103            12.795596   \n26            12.565305            12.600430            12.764371   \n27            12.474641            12.471794            12.904288   \n31            12.530703            12.503940            12.791145   \n32                  NaN                  NaN                  NaN   \n33            12.481790            12.456831            13.131979   \n35            12.588375            12.506773                  NaN   \n36            12.488005            12.546289            12.861138   \n38            12.629846            12.642667            13.134355   \n\n    HPA045702_SBA4_rep1  HPA048982_SBA4_rep1  \n5             12.696679            12.602999  \n6             12.514924            12.618601  \n8             12.554774            12.587261  \n9             12.532538            12.661084  \n16            12.578293            12.685735  \n18            12.541253            12.606741  \n21            12.552749            12.618074  \n26            12.561835                  NaN  \n27            12.526909                  NaN  \n31            12.471993            12.604703  \n32                  NaN                  NaN  \n33            12.578485                  NaN  \n35            12.445122                  NaN  \n36            12.520447                  NaN  \n38            12.628539            12.773149  \n\n[15 rows x 976 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Sample_ID</th>\n      <th>Participant_ID</th>\n      <th>Dataset</th>\n      <th>Disease</th>\n      <th>Age</th>\n      <th>FT1</th>\n      <th>FT2</th>\n      <th>FT3</th>\n      <th>FT4</th>\n      <th>...</th>\n      <th>HPA049320_SBA4_rep1</th>\n      <th>HPA051620_SBA4_rep1</th>\n      <th>HPA054862_SBA4_rep1</th>\n      <th>HPA003901_SBA4_rep1</th>\n      <th>HPA035863_SBA4_rep1</th>\n      <th>HPA040052_SBA4_rep1</th>\n      <th>HPA041542_SBA4_rep1</th>\n      <th>HPA044582_SBA4_rep1</th>\n      <th>HPA045702_SBA4_rep1</th>\n      <th>HPA048982_SBA4_rep1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>S237</td>\n      <td>P5</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>11.72</td>\n      <td>2.538071</td>\n      <td>0.628931</td>\n      <td>0.367647</td>\n      <td>488.7</td>\n      <td>...</td>\n      <td>12.543301</td>\n      <td>12.608368</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.598509</td>\n      <td>12.452527</td>\n      <td>12.495444</td>\n      <td>12.800951</td>\n      <td>12.696679</td>\n      <td>12.602999</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>S220</td>\n      <td>P5</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>13.41</td>\n      <td>2.531646</td>\n      <td>0.492611</td>\n      <td>0.275482</td>\n      <td>475.0</td>\n      <td>...</td>\n      <td>12.390816</td>\n      <td>12.571472</td>\n      <td>12.389882</td>\n      <td>12.490296</td>\n      <td>12.522449</td>\n      <td>12.519723</td>\n      <td>12.413517</td>\n      <td>12.917533</td>\n      <td>12.514924</td>\n      <td>12.618601</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>S91</td>\n      <td>P6</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>11.76</td>\n      <td>2.237136</td>\n      <td>0.346021</td>\n      <td>0.176991</td>\n      <td>449.0</td>\n      <td>...</td>\n      <td>12.464468</td>\n      <td>12.599863</td>\n      <td>12.459217</td>\n      <td>12.509688</td>\n      <td>12.482434</td>\n      <td>12.507582</td>\n      <td>12.593243</td>\n      <td>12.733109</td>\n      <td>12.554774</td>\n      <td>12.587261</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>S49</td>\n      <td>P134</td>\n      <td>DNHS</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.560804</td>\n      <td>12.531565</td>\n      <td>12.490397</td>\n      <td>12.419143</td>\n      <td>12.585085</td>\n      <td>12.509866</td>\n      <td>12.386933</td>\n      <td>12.820761</td>\n      <td>12.532538</td>\n      <td>12.661084</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>S79</td>\n      <td>P134</td>\n      <td>DNHS</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.583934</td>\n      <td>12.599499</td>\n      <td>12.527210</td>\n      <td>12.636333</td>\n      <td>12.440678</td>\n      <td>12.555278</td>\n      <td>12.617759</td>\n      <td>12.909895</td>\n      <td>12.578293</td>\n      <td>12.685735</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>S70</td>\n      <td>P135</td>\n      <td>DNHS</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.456166</td>\n      <td>12.597872</td>\n      <td>12.496037</td>\n      <td>12.652614</td>\n      <td>12.457952</td>\n      <td>12.487103</td>\n      <td>12.521334</td>\n      <td>12.823034</td>\n      <td>12.541253</td>\n      <td>12.606741</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>S2</td>\n      <td>P135</td>\n      <td>DNHS</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.481201</td>\n      <td>12.621694</td>\n      <td>12.415145</td>\n      <td>12.616261</td>\n      <td>12.450933</td>\n      <td>12.536485</td>\n      <td>12.559103</td>\n      <td>12.795596</td>\n      <td>12.552749</td>\n      <td>12.618074</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>S83</td>\n      <td>P136</td>\n      <td>DNHS</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.403677</td>\n      <td>12.545281</td>\n      <td>NaN</td>\n      <td>12.439043</td>\n      <td>12.489224</td>\n      <td>12.565305</td>\n      <td>12.600430</td>\n      <td>12.764371</td>\n      <td>12.561835</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>S41</td>\n      <td>P136</td>\n      <td>DNHS</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.391321</td>\n      <td>12.450349</td>\n      <td>12.378164</td>\n      <td>12.358069</td>\n      <td>12.510605</td>\n      <td>12.474641</td>\n      <td>12.471794</td>\n      <td>12.904288</td>\n      <td>12.526909</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>32</td>\n      <td>S276</td>\n      <td>P7</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>10.90</td>\n      <td>1.461988</td>\n      <td>0.155763</td>\n      <td>0.114155</td>\n      <td>317.0</td>\n      <td>...</td>\n      <td>12.476450</td>\n      <td>12.425208</td>\n      <td>NaN</td>\n      <td>12.397139</td>\n      <td>12.523445</td>\n      <td>12.530703</td>\n      <td>12.503940</td>\n      <td>12.791145</td>\n      <td>12.471993</td>\n      <td>12.604703</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>33</td>\n      <td>S302</td>\n      <td>P7</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>11.94</td>\n      <td>0.995025</td>\n      <td>0.117233</td>\n      <td>0.093284</td>\n      <td>150.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.397159</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>34</td>\n      <td>S351</td>\n      <td>P7</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>12.67</td>\n      <td>0.923361</td>\n      <td>0.092764</td>\n      <td>0.070972</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.476410</td>\n      <td>12.483707</td>\n      <td>NaN</td>\n      <td>12.294553</td>\n      <td>12.562372</td>\n      <td>12.481790</td>\n      <td>12.456831</td>\n      <td>13.131979</td>\n      <td>12.578485</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>36</td>\n      <td>S348</td>\n      <td>P9</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>11.12</td>\n      <td>NaN</td>\n      <td>0.196078</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>12.428524</td>\n      <td>12.626223</td>\n      <td>NaN</td>\n      <td>12.414213</td>\n      <td>12.507686</td>\n      <td>12.588375</td>\n      <td>12.506773</td>\n      <td>NaN</td>\n      <td>12.445122</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>37</td>\n      <td>S286</td>\n      <td>P9</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>12.03</td>\n      <td>1.020408</td>\n      <td>0.112360</td>\n      <td>NaN</td>\n      <td>75.0</td>\n      <td>...</td>\n      <td>12.380450</td>\n      <td>12.483917</td>\n      <td>NaN</td>\n      <td>12.590108</td>\n      <td>12.615858</td>\n      <td>12.488005</td>\n      <td>12.546289</td>\n      <td>12.861138</td>\n      <td>12.520447</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>39</td>\n      <td>S273</td>\n      <td>P10</td>\n      <td>DNHS</td>\n      <td>1.0</td>\n      <td>11.58</td>\n      <td>0.869565</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>209.0</td>\n      <td>...</td>\n      <td>12.488839</td>\n      <td>12.597753</td>\n      <td>12.562960</td>\n      <td>12.415403</td>\n      <td>12.642297</td>\n      <td>12.629846</td>\n      <td>12.642667</td>\n      <td>13.134355</td>\n      <td>12.628539</td>\n      <td>12.773149</td>\n    </tr>\n  </tbody>\n</table>\n<p>15 rows × 976 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with NaN values in the FT5 column\n",
    "not_na = dataset['FT5'].notna()\n",
    "indices_to_drop = not_na[not_na == False].index\n",
    "\n",
    "# Check changes\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "dataset.drop(indices_to_drop, inplace=True)\n",
    "print(\"After drop:\", dataset.shape)\n",
    "\n",
    "dataset.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Northstar Prediction Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle Missing Values:\n",
    "Before anything can be done, ensure all NaN values are handled appropriately, either by imputation or by removing rows/columns with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:47.755226Z",
     "start_time": "2024-04-09T11:06:46.879583Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Isolate relevant data\n",
    "d = dataset.iloc[:, 10:] \n",
    "\n",
    "# Option 1: Impute missing values (e.g., with the mean of each column)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(d), columns=d.columns)\n",
    "\n",
    "# Option 2: Drop rows with any NaN values (use with caution)\n",
    "# df_dropped = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:47.766981Z",
     "start_time": "2024-04-09T11:06:47.756237Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df_imputed['FT5'] # Vector for the target variable\n",
    "X = df_imputed.iloc[:, 1:] # Matrix with variable input\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Univariate Feature Selection\n",
    "This method selects the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:47.822144Z",
     "start_time": "2024-04-09T11:06:47.767989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features Shape: (240, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Select the top 100 features based on ANOVA F-value\n",
    "select_k_best = SelectKBest(f_classif, k=100)\n",
    "X_train_selected = select_k_best.fit_transform(X_train, y_train)\n",
    "X_test_selected = select_k_best.transform(X_test)\n",
    "\n",
    "print(\"Selected Features Shape:\", X_train_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Selection Using Model\n",
    "You can use a model to determine the importance of each feature and select the most important features accordingly. Here, we'll use ExtraTreesClassifier as an example for classification. For regression tasks, you could use ExtraTreesRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:06:48.106054Z",
     "start_time": "2024-04-09T11:06:47.823150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Selected Features Shape: (240, 451)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Noah\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=50)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "# Model-based feature selection\n",
    "model_select = SelectFromModel(model, prefit=True)\n",
    "X_train_model = model_select.transform(X_train)\n",
    "X_test_model = model_select.transform(X_test)\n",
    "\n",
    "print(\"Model Selected Features Shape:\", X_train_model.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recursive Feature Elimination (RFE)\n",
    "RFE works by recursively removing the least important feature and building a model on those features that remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:07:11.949269Z",
     "start_time": "2024-04-09T11:06:48.107060Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Initialize RFE and select the top 100 features\u001B[39;00m\n\u001B[0;32m      8\u001B[0m rfe \u001B[38;5;241m=\u001B[39m RFE(estimator\u001B[38;5;241m=\u001B[39mmodel, n_features_to_select\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m X_train_rfe \u001B[38;5;241m=\u001B[39m \u001B[43mrfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m X_test_rfe \u001B[38;5;241m=\u001B[39m rfe\u001B[38;5;241m.\u001B[39mtransform(X_test)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRFE Selected Features Shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, X_train_rfe\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 295\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    296\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    297\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    298\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    299\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    300\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    301\u001B[0m         )\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\base.py:1101\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m   1098\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1100\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[1;32m-> 1101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:264\u001B[0m, in \u001B[0;36mRFE.fit\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    244\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001B[39;00m\n\u001B[0;32m    245\u001B[0m \n\u001B[0;32m    246\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    261\u001B[0m \u001B[38;5;124;03m    Fitted estimator.\u001B[39;00m\n\u001B[0;32m    262\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    263\u001B[0m _raise_for_unsupported_routing(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m--> 264\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:311\u001B[0m, in \u001B[0;36mRFE._fit\u001B[1;34m(self, X, y, step_score, **fit_params)\u001B[0m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    309\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting estimator with \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m features.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m np\u001B[38;5;241m.\u001B[39msum(support_))\n\u001B[1;32m--> 311\u001B[0m \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;66;03m# Get importance and rank them\u001B[39;00m\n\u001B[0;32m    314\u001B[0m importances \u001B[38;5;241m=\u001B[39m _get_feature_importances(\n\u001B[0;32m    315\u001B[0m     estimator,\n\u001B[0;32m    316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimportance_getter,\n\u001B[0;32m    317\u001B[0m     transform_func\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msquare\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    318\u001B[0m )\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1293\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1294\u001B[0m     n_threads \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1296\u001B[0m fold_coefs_ \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprefer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1297\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1298\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1299\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1300\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1301\u001B[0m \u001B[43m        \u001B[49m\u001B[43mCs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mC_\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1302\u001B[0m \u001B[43m        \u001B[49m\u001B[43ml1_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ml1_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1303\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1305\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1306\u001B[0m \u001B[43m        \u001B[49m\u001B[43msolver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1307\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1309\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1310\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoef\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpenalty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpenalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_squared_sum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_squared_sum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1315\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_threads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_threads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1317\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1318\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mclasses_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1319\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1321\u001B[0m fold_coefs_, _, n_iter_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mfold_coefs_)\n\u001B[0;32m   1322\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(n_iter_, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint32)[:, \u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\joblib\\parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\joblib\\parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    127\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:455\u001B[0m, in \u001B[0;36m_logistic_regression_path\u001B[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001B[0m\n\u001B[0;32m    451\u001B[0m l2_reg_strength \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m (C \u001B[38;5;241m*\u001B[39m sw_sum)\n\u001B[0;32m    452\u001B[0m iprint \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m101\u001B[39m][\n\u001B[0;32m    453\u001B[0m     np\u001B[38;5;241m.\u001B[39msearchsorted(np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m]), verbose)\n\u001B[0;32m    454\u001B[0m ]\n\u001B[1;32m--> 455\u001B[0m opt_res \u001B[38;5;241m=\u001B[39m \u001B[43moptimize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m    \u001B[49m\u001B[43mw0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mL-BFGS-B\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml2_reg_strength\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_threads\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m    462\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaxiter\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    463\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaxls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# default is 20\u001B[39;49;00m\n\u001B[0;32m    464\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43miprint\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43miprint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    465\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgtol\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    466\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mftol\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfinfo\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    468\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    469\u001B[0m n_iter_i \u001B[38;5;241m=\u001B[39m _check_optimize_result(\n\u001B[0;32m    470\u001B[0m     solver,\n\u001B[0;32m    471\u001B[0m     opt_res,\n\u001B[0;32m    472\u001B[0m     max_iter,\n\u001B[0;32m    473\u001B[0m     extra_warning_msg\u001B[38;5;241m=\u001B[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001B[0;32m    474\u001B[0m )\n\u001B[0;32m    475\u001B[0m w0, loss \u001B[38;5;241m=\u001B[39m opt_res\u001B[38;5;241m.\u001B[39mx, opt_res\u001B[38;5;241m.\u001B[39mfun\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:713\u001B[0m, in \u001B[0;36mminimize\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[0;32m    710\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[0;32m    711\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    712\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml-bfgs-b\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 713\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_minimize_lbfgsb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    714\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    715\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtnc\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    716\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[0;32m    717\u001B[0m                         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[1;32m~\\repos\\KEX-DA150x-KTH\\venv\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:401\u001B[0m, in \u001B[0;36m_minimize_lbfgsb\u001B[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[0;32m    397\u001B[0m \u001B[38;5;66;03m# x, f, g, wa, iwa, task, csave, lsave, isave, dsave = \\\u001B[39;00m\n\u001B[0;32m    398\u001B[0m _lbfgsb\u001B[38;5;241m.\u001B[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n\u001B[0;32m    399\u001B[0m                pgtol, wa, iwa, task, iprint, csave, lsave,\n\u001B[0;32m    400\u001B[0m                isave, dsave, maxls)\n\u001B[1;32m--> 401\u001B[0m task_str \u001B[38;5;241m=\u001B[39m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtobytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFG\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;66;03m# The minimization routine wants f and g at the current x.\u001B[39;00m\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001B[39;00m\n\u001B[0;32m    405\u001B[0m     \u001B[38;5;66;03m# until the completion of the current minimization iteration.\u001B[39;00m\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;66;03m# Overwrite f and g:\u001B[39;00m\n\u001B[0;32m    407\u001B[0m     f, g \u001B[38;5;241m=\u001B[39m func_and_grad(x)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model to be used\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Initialize RFE and select the top 100 features\n",
    "rfe = RFE(estimator=model, n_features_to_select=100, step=1)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "print(\"RFE Selected Features Shape:\", X_train_rfe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:07:40.959050Z",
     "start_time": "2024-04-09T11:07:40.479329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "SVC()",
      "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the important packages\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Build the model\n",
    "# TODO: try probability=True\n",
    "svm = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None)\n",
    "\n",
    "# Trained the model\n",
    "svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "QP-jazpobWuT",
    "outputId": "c600c891-f03a-40dd-dc42-9b5fe8828e60"
   },
   "outputs": [],
   "source": [
    "# Get summary statistics for whole data set\n",
    "max = dataset.max(axis=None)\n",
    "min = dataset.min(axis=None)\n",
    "median = dataset.median(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "3NOPw1kbfr3d",
    "outputId": "01955389-03ac-4ae4-e8b3-98924b0dce11",
    "ExecuteTime": {
     "end_time": "2024-04-09T11:07:11.953277Z",
     "start_time": "2024-04-09T11:07:11.953277Z"
    }
   },
   "outputs": [],
   "source": [
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "EeXcB6GFE30h",
    "outputId": "efd87f3f-6b66-45dc-e5e7-3269582a7c25",
    "ExecuteTime": {
     "start_time": "2024-04-09T11:07:11.954275Z"
    }
   },
   "outputs": [],
   "source": [
    "print(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "LiItUIv2E397",
    "outputId": "e5382aab-b6b3-4441-b103-b58460919818",
    "ExecuteTime": {
     "start_time": "2024-04-09T11:07:11.955277Z"
    }
   },
   "outputs": [],
   "source": [
    "print(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "12FnOCJjFAQ1",
    "ExecuteTime": {
     "start_time": "2024-04-09T11:07:11.956276Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "ipCmokfYJ2jb",
    "outputId": "a5dc0b64-f81a-4726-e46d-70f75a598129",
    "ExecuteTime": {
     "start_time": "2024-04-09T11:07:11.957277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get protein intensitiy values only by removing first 15 columns\n",
    "intensities = dataset.iloc[:, 14:]\n",
    "# print(intensities)\n",
    "\n",
    "# Calculate min, max, and median for intensities\n",
    "min_values = intensities.min()\n",
    "max_values = intensities.max()\n",
    "median_values = intensities.median()\n",
    "\n",
    "# Now, calculate the average of these statistics across the columns\n",
    "global_min = min_values.min()\n",
    "global_max = max_values.max()\n",
    "global_median = median_values.mean()\n",
    "\n",
    "print(\"Global maximum intensity:\", global_max)\n",
    "print(\"Global median intensity:\", global_median)\n",
    "print(\"Global minimum intensity:\", global_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1710344581052,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "oCNK1_JeKt06",
    "outputId": "0284d031-559c-4e50-f024-ca01909775db"
   },
   "outputs": [],
   "source": [
    "# Normalize protein intensities in dataset\n",
    "\"\"\"\n",
    " OBS: we do not want to do this initially\n",
    "      also it might make the  model less useful\n",
    "      since it makes intensities from other\n",
    "      studies or clinical samples harder to\n",
    "      compare.\n",
    "\n",
    "      Also, we are normalizing the intensities globally instead of per-column\n",
    "      (per-protein). Would doing it per protein be better?\n",
    "\n",
    "      Disabled for now.\n",
    "\"\"\"\n",
    "# dataset.iloc[:, 14:] = (dataset.iloc[:, 14:] - global_min) / (global_max - global_min)\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1710344581052,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "lXDPhBhkMelA",
    "outputId": "bfebf9ce-4413-4217-edef-a724b13670f9",
    "ExecuteTime": {
     "start_time": "2024-04-09T11:07:11.960275Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop physical tests (might include them in the future)\n",
    "columns_to_drop = dataset.columns[7:12]\n",
    "dataset = dataset.drop(columns=columns_to_drop)\n",
    "\n",
    "print(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1710344581052,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "omE-rJqLPIgB",
    "outputId": "3459a43a-f3a1-4329-ebb2-f1f910bd9cfa"
   },
   "outputs": [],
   "source": [
    "# Print final dataset\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1710344581052,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "Bof-xPCuyVkW",
    "outputId": "df017fb6-8373-44b6-c237-704bd1430bae",
    "ExecuteTime": {
     "start_time": "2024-04-09T11:07:11.963276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create list of training vectors consisting of age and protein intensities\n",
    "\n",
    "columns = dataset.columns\n",
    "# print(columns)\n",
    "\n",
    "# Select specific columns (in this case only 5) and then from 9 through the last column\n",
    "dataset_ANN_vectors = dataset.iloc[:, [5] + list(range(9, dataset.shape[1]))]\n",
    "\n",
    "print(dataset_ANN_vectors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1710344581052,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "WLS_cxMLgJqO",
    "ExecuteTime": {
     "start_time": "2024-04-09T11:07:11.964278Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.loadtxt(dataset, delimiter=\",\", skiprows=0)\n",
    "\n",
    "# r = np.genfromtxt(dataset, delimiter=',', names=True, case_sensitive=True)\n",
    "# print(repr(r))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
