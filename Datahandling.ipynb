{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNIZ0oiqVv8q"
   },
   "source": [
    "# Data Processing\n",
    "\n",
    "Data visualization, cleaning, division, and normalization.\n",
    "\n",
    "* Execute small adjustments/renaming of columns\n",
    "* Disease parameter: DMD/Cnt -> 1/0\n",
    "* Remove rows if:\n",
    "  * Sample.ID's value is \"BLANK\", \"POOL 1\" or \"POOL 2\"\n",
    "  * Disease or Sample.ID value for row is missing  \n",
    "* If there are multiple rows with same Sample.ID, drop the duplicate rows with fewer value entires\n",
    "  * Might need to evalueate manually or reevaluate the heuristiics (which proteins to prioritize over others)\n",
    "* Remove columns of antibody consentrations if there are no data entries\n",
    "\n",
    "* TODO: debugg, continue with later points\n",
    "* Potentionally normalize intensities: [-1, 1] or [0, 1]\n",
    "* Create new column for LoA based on FT1-5 \n",
    "\n",
    "* Flytta om ordningen på kolumnerna så att varje rad blir en vektor på formen <<METADATA>,<Y>,<X>> där <X> är [LoA], <Y> är intensiteterna (och eventuellt ålder senare) och <METADATA> är allt annat.\n",
    "\n",
    "* Run a SVM with our input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviroment to read and process DMD data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeiNQxvnXphM"
   },
   "source": [
    "Imports used for data processing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1710344580569,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "7Y_AEHs1hXrm",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhloDaQfbCZK"
   },
   "source": [
    "Load CSV file through pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "lUDzHuv3Xxcm",
    "outputId": "c9cdef14-583c-495f-e44c-a0ea72be5bdb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sample.ID</th>\n",
       "      <th>Participant.ID</th>\n",
       "      <th>dataset</th>\n",
       "      <th>Disease</th>\n",
       "      <th>patregag</th>\n",
       "      <th>TREAT</th>\n",
       "      <th>FT1</th>\n",
       "      <th>FT2</th>\n",
       "      <th>FT3</th>\n",
       "      <th>...</th>\n",
       "      <th>HPA049320_SBA4_rep1</th>\n",
       "      <th>HPA051620_SBA4_rep1</th>\n",
       "      <th>HPA054862_SBA4_rep1</th>\n",
       "      <th>HPA003901_SBA4_rep1</th>\n",
       "      <th>HPA035863_SBA4_rep1</th>\n",
       "      <th>HPA040052_SBA4_rep1</th>\n",
       "      <th>HPA041542_SBA4_rep1</th>\n",
       "      <th>HPA044582_SBA4_rep1</th>\n",
       "      <th>HPA045702_SBA4_rep1</th>\n",
       "      <th>HPA048982_SBA4_rep1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S87</td>\n",
       "      <td>P3</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>DMD</td>\n",
       "      <td>11.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.476497</td>\n",
       "      <td>12.666707</td>\n",
       "      <td>12.331400</td>\n",
       "      <td>12.410101</td>\n",
       "      <td>12.504796</td>\n",
       "      <td>12.580695</td>\n",
       "      <td>12.574592</td>\n",
       "      <td>12.797013</td>\n",
       "      <td>12.492433</td>\n",
       "      <td>12.622226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>S10</td>\n",
       "      <td>P3</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>DMD</td>\n",
       "      <td>12.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.494297</td>\n",
       "      <td>12.564169</td>\n",
       "      <td>12.354718</td>\n",
       "      <td>12.581718</td>\n",
       "      <td>12.441237</td>\n",
       "      <td>12.583769</td>\n",
       "      <td>12.579893</td>\n",
       "      <td>12.660894</td>\n",
       "      <td>12.450384</td>\n",
       "      <td>12.704464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>S19</td>\n",
       "      <td>P3</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>DMD</td>\n",
       "      <td>13.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.554581</td>\n",
       "      <td>12.707240</td>\n",
       "      <td>12.460004</td>\n",
       "      <td>12.610387</td>\n",
       "      <td>12.504661</td>\n",
       "      <td>12.556319</td>\n",
       "      <td>12.679701</td>\n",
       "      <td>12.824755</td>\n",
       "      <td>12.517335</td>\n",
       "      <td>12.836970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>S137</td>\n",
       "      <td>P4</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>DMD</td>\n",
       "      <td>11.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.455811</td>\n",
       "      <td>12.505603</td>\n",
       "      <td>12.416459</td>\n",
       "      <td>12.510771</td>\n",
       "      <td>12.472934</td>\n",
       "      <td>12.556096</td>\n",
       "      <td>12.473760</td>\n",
       "      <td>12.744020</td>\n",
       "      <td>12.511776</td>\n",
       "      <td>12.666065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>S182</td>\n",
       "      <td>P4</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>DMD</td>\n",
       "      <td>13.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.523768</td>\n",
       "      <td>12.598164</td>\n",
       "      <td>12.369592</td>\n",
       "      <td>12.605211</td>\n",
       "      <td>12.523768</td>\n",
       "      <td>12.503911</td>\n",
       "      <td>12.557672</td>\n",
       "      <td>12.926602</td>\n",
       "      <td>12.518327</td>\n",
       "      <td>12.668579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1039 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Sample.ID Participant.ID dataset Disease  patregag TREAT  FT1  FT2  FT3  \\\n",
       "0   1       S87             P3    DNHS     DMD     11.61   NaN  0.0  0.0  NaN   \n",
       "1   2       S10             P3    DNHS     DMD     12.62   NaN  NaN  NaN  NaN   \n",
       "2   3       S19             P3    DNHS     DMD     13.62   NaN  NaN  NaN  NaN   \n",
       "3   4      S137             P4    DNHS     DMD     11.43   NaN  NaN  NaN  NaN   \n",
       "4   5      S182             P4    DNHS     DMD     13.25   NaN  NaN  NaN  NaN   \n",
       "\n",
       "   ...  HPA049320_SBA4_rep1  HPA051620_SBA4_rep1  HPA054862_SBA4_rep1  \\\n",
       "0  ...            12.476497            12.666707            12.331400   \n",
       "1  ...            12.494297            12.564169            12.354718   \n",
       "2  ...            12.554581            12.707240            12.460004   \n",
       "3  ...            12.455811            12.505603            12.416459   \n",
       "4  ...            12.523768            12.598164            12.369592   \n",
       "\n",
       "  HPA003901_SBA4_rep1  HPA035863_SBA4_rep1  HPA040052_SBA4_rep1  \\\n",
       "0           12.410101            12.504796            12.580695   \n",
       "1           12.581718            12.441237            12.583769   \n",
       "2           12.610387            12.504661            12.556319   \n",
       "3           12.510771            12.472934            12.556096   \n",
       "4           12.605211            12.523768            12.503911   \n",
       "\n",
       "   HPA041542_SBA4_rep1  HPA044582_SBA4_rep1  HPA045702_SBA4_rep1  \\\n",
       "0            12.574592            12.797013            12.492433   \n",
       "1            12.579893            12.660894            12.450384   \n",
       "2            12.679701            12.824755            12.517335   \n",
       "3            12.473760            12.744020            12.511776   \n",
       "4            12.557672            12.926602            12.518327   \n",
       "\n",
       "   HPA048982_SBA4_rep1  \n",
       "0            12.622226  \n",
       "1            12.704464  \n",
       "2            12.836970  \n",
       "3            12.666065  \n",
       "4            12.668579  \n",
       "\n",
       "[5 rows x 1039 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('normalised_data_all_w_clinical_kex_20240321.csv')\n",
    "dataset.head() # Pre-view first five rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mU1AUw0annb"
   },
   "source": [
    "## First Data Visualization & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Sample_ID', 'Participant_ID', 'Dataset', 'Disease', 'Age',\n",
      "       'TREAT', 'FT1', 'FT2', 'FT3',\n",
      "       ...\n",
      "       'HPA049320_SBA4_rep1', 'HPA051620_SBA4_rep1', 'HPA054862_SBA4_rep1',\n",
      "       'HPA003901_SBA4_rep1', 'HPA035863_SBA4_rep1', 'HPA040052_SBA4_rep1',\n",
      "       'HPA041542_SBA4_rep1', 'HPA044582_SBA4_rep1', 'HPA045702_SBA4_rep1',\n",
      "       'HPA048982_SBA4_rep1'],\n",
      "      dtype='object', length=1039)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarar\\AppData\\Local\\Temp\\ipykernel_7036\\2412043818.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset['Disease'] = dataset['Disease'].replace(token_to_val)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Age</th>\n",
       "      <th>TREAT</th>\n",
       "      <th>FT1</th>\n",
       "      <th>FT2</th>\n",
       "      <th>FT3</th>\n",
       "      <th>...</th>\n",
       "      <th>HPA049320_SBA4_rep1</th>\n",
       "      <th>HPA051620_SBA4_rep1</th>\n",
       "      <th>HPA054862_SBA4_rep1</th>\n",
       "      <th>HPA003901_SBA4_rep1</th>\n",
       "      <th>HPA035863_SBA4_rep1</th>\n",
       "      <th>HPA040052_SBA4_rep1</th>\n",
       "      <th>HPA041542_SBA4_rep1</th>\n",
       "      <th>HPA044582_SBA4_rep1</th>\n",
       "      <th>HPA045702_SBA4_rep1</th>\n",
       "      <th>HPA048982_SBA4_rep1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S87</td>\n",
       "      <td>P3</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.476497</td>\n",
       "      <td>12.666707</td>\n",
       "      <td>12.331400</td>\n",
       "      <td>12.410101</td>\n",
       "      <td>12.504796</td>\n",
       "      <td>12.580695</td>\n",
       "      <td>12.574592</td>\n",
       "      <td>12.797013</td>\n",
       "      <td>12.492433</td>\n",
       "      <td>12.622226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>S10</td>\n",
       "      <td>P3</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.494297</td>\n",
       "      <td>12.564169</td>\n",
       "      <td>12.354718</td>\n",
       "      <td>12.581718</td>\n",
       "      <td>12.441237</td>\n",
       "      <td>12.583769</td>\n",
       "      <td>12.579893</td>\n",
       "      <td>12.660894</td>\n",
       "      <td>12.450384</td>\n",
       "      <td>12.704464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>S19</td>\n",
       "      <td>P3</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.554581</td>\n",
       "      <td>12.707240</td>\n",
       "      <td>12.460004</td>\n",
       "      <td>12.610387</td>\n",
       "      <td>12.504661</td>\n",
       "      <td>12.556319</td>\n",
       "      <td>12.679701</td>\n",
       "      <td>12.824755</td>\n",
       "      <td>12.517335</td>\n",
       "      <td>12.836970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>S137</td>\n",
       "      <td>P4</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.455811</td>\n",
       "      <td>12.505603</td>\n",
       "      <td>12.416459</td>\n",
       "      <td>12.510771</td>\n",
       "      <td>12.472934</td>\n",
       "      <td>12.556096</td>\n",
       "      <td>12.473760</td>\n",
       "      <td>12.744020</td>\n",
       "      <td>12.511776</td>\n",
       "      <td>12.666065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>S182</td>\n",
       "      <td>P4</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.523768</td>\n",
       "      <td>12.598164</td>\n",
       "      <td>12.369592</td>\n",
       "      <td>12.605211</td>\n",
       "      <td>12.523768</td>\n",
       "      <td>12.503911</td>\n",
       "      <td>12.557672</td>\n",
       "      <td>12.926602</td>\n",
       "      <td>12.518327</td>\n",
       "      <td>12.668579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1039 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Sample_ID Participant_ID Dataset  Disease    Age TREAT  FT1  FT2  FT3  \\\n",
       "0   1       S87             P3    DNHS      1.0  11.61   NaN  0.0  0.0  NaN   \n",
       "1   2       S10             P3    DNHS      1.0  12.62   NaN  NaN  NaN  NaN   \n",
       "2   3       S19             P3    DNHS      1.0  13.62   NaN  NaN  NaN  NaN   \n",
       "3   4      S137             P4    DNHS      1.0  11.43   NaN  NaN  NaN  NaN   \n",
       "4   5      S182             P4    DNHS      1.0  13.25   NaN  NaN  NaN  NaN   \n",
       "\n",
       "   ...  HPA049320_SBA4_rep1  HPA051620_SBA4_rep1  HPA054862_SBA4_rep1  \\\n",
       "0  ...            12.476497            12.666707            12.331400   \n",
       "1  ...            12.494297            12.564169            12.354718   \n",
       "2  ...            12.554581            12.707240            12.460004   \n",
       "3  ...            12.455811            12.505603            12.416459   \n",
       "4  ...            12.523768            12.598164            12.369592   \n",
       "\n",
       "  HPA003901_SBA4_rep1  HPA035863_SBA4_rep1  HPA040052_SBA4_rep1  \\\n",
       "0           12.410101            12.504796            12.580695   \n",
       "1           12.581718            12.441237            12.583769   \n",
       "2           12.610387            12.504661            12.556319   \n",
       "3           12.510771            12.472934            12.556096   \n",
       "4           12.605211            12.523768            12.503911   \n",
       "\n",
       "   HPA041542_SBA4_rep1  HPA044582_SBA4_rep1  HPA045702_SBA4_rep1  \\\n",
       "0            12.574592            12.797013            12.492433   \n",
       "1            12.579893            12.660894            12.450384   \n",
       "2            12.679701            12.824755            12.517335   \n",
       "3            12.473760            12.744020            12.511776   \n",
       "4            12.557672            12.926602            12.518327   \n",
       "\n",
       "   HPA048982_SBA4_rep1  \n",
       "0            12.622226  \n",
       "1            12.704464  \n",
       "2            12.836970  \n",
       "3            12.666065  \n",
       "4            12.668579  \n",
       "\n",
       "[5 rows x 1039 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Dictionary for value conversion\n",
    "token_to_val = {\n",
    "    \"DMD\": 1,\n",
    "    \"Cnt\": 0\n",
    "}\n",
    "# Rename columns\n",
    "dataset.rename(columns={dataset.columns[0]: 'ID'}, inplace=True)\n",
    "dataset.rename(columns={'Sample.ID': 'Sample_ID'}, inplace=True)\n",
    "dataset.rename(columns={'Participant.ID': 'Participant_ID'}, inplace=True)\n",
    "dataset.rename(columns={'dataset': 'Dataset'}, inplace=True)\n",
    "dataset.rename(columns={'patregag': 'Age'}, inplace=True)\n",
    "\n",
    "# Replace the string values in the column using the mapping in token_to_val\n",
    "dataset['Disease'] = dataset['Disease'].replace(token_to_val)\n",
    "\n",
    "# Verify the change\n",
    "print(dataset.columns)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         FT1       FT2       FT3    FT4   FT5\n",
      "0   0.000000  0.000000       NaN    NaN   NaN\n",
      "1        NaN       NaN       NaN    NaN   NaN\n",
      "2        NaN       NaN       NaN    NaN   NaN\n",
      "3        NaN       NaN       NaN    NaN   NaN\n",
      "4        NaN       NaN       NaN    NaN   NaN\n",
      "5   2.538071  0.628931  0.367647  488.7  32.0\n",
      "6   2.531646  0.492611  0.275482  475.0  29.0\n",
      "7        NaN       NaN       NaN    NaN   NaN\n",
      "8   2.237136  0.346021  0.176991  449.0  31.0\n",
      "9        NaN       NaN       NaN    NaN  34.0\n",
      "10       NaN       NaN       NaN    NaN  34.0\n",
      "11       NaN       NaN       NaN    NaN  34.0\n",
      "12       NaN       NaN       NaN    NaN  34.0\n",
      "13       NaN       NaN       NaN    NaN  34.0\n",
      "14       NaN       NaN       NaN    NaN  34.0\n"
     ]
    }
   ],
   "source": [
    "# Give control group (non DMD) default value of 34 (top score) on FT5\n",
    "in_control = dataset['Disease']  == 0.0\n",
    "control_index = in_control[in_control == True].index\n",
    "dataset.loc[control_index, 'FT5'] = 34\n",
    "\n",
    "# Verify the change\n",
    "print(dataset.iloc[:15, 7:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Based Data Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_column_value_percentage(df, start_column=1):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of actual (non-NA) data points for each column in a pandas DataFrame\n",
    "    within a specified interval.\n",
    "\n",
    "    :param df: A pandas DataFrame with potential NA values.\n",
    "    :param start_column: The starting column index for the interval (1-based index).\n",
    "    :param end_column: The ending column index for the interval. If None, calculates up to the last column.\n",
    "    :return: A pandas Series with the percentage of non-NA values for each column in the interval.\n",
    "    \"\"\"\n",
    "    # Adjust for 0-based indexing\n",
    "    start_index = max(0, start_column - 1)\n",
    "\n",
    "    # Select only the columns within the specified interval\n",
    "    interval_df = df.iloc[:, start_index:]\n",
    "\n",
    "    # Calculate the total number of non-NA values for each column\n",
    "    value_counts = interval_df.count()\n",
    "\n",
    "    # Calculate the total number of rows (to handle potential NA rows)\n",
    "    total_rows = len(df)\n",
    "\n",
    "    # Calculate the percentage of non-NA values for each column\n",
    "    value_percentage = (value_counts / total_rows) * 100\n",
    "\n",
    "    return value_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column HPA003948_SBA1_rep1 has 0.00% values\n",
      "Column HPA059806_SBA1_rep1 has 11.20% values\n",
      "Column HPA055893_SBA2_rep1 has 41.15% values\n",
      "Column HPA035933_SBA2_rep1 has 33.07% values\n",
      "Column HPA009426_SBA2_rep1 has 32.29% values\n",
      "Column HPA057437_SBA3_rep1 has 0.00% values\n",
      "Column HPA003909_SBA3_rep1 has 15.89% values\n",
      "Column HPA015774_SBA3_rep1 has 42.45% values\n",
      "Column HPA003223_SBA3_rep1 has 6.77% values\n",
      "Column HPA003948_SBA3_rep1 has 0.00% values\n",
      "Column Empty_SBA3_rep1 has 8.85% values\n",
      "Column HPA040591_SBA3_rep1 has 30.99% values\n",
      "Column HPA034960_SBA3_rep1 has 0.00% values\n",
      "Column HPA021513_SBA3_rep1 has 43.75% values\n",
      "Column HPA058513_SBA3_rep1 has 0.00% values\n",
      "Column HPA036287_SBA3_rep1 has 11.46% values\n",
      "Column HPA073315_SBA3_rep1 has 13.54% values\n",
      "Column HPA041863_SBA3_rep1 has 34.38% values\n",
      "Column HPA004712_SBA3_rep1 has 34.64% values\n",
      "Column HPA074922_SBA3_rep1 has 0.00% values\n",
      "Column HPA000837_SBA4_rep1 has 0.00% values\n",
      "Column HPA001482_SBA4_rep1 has 0.00% values\n",
      "Column HPA000293_SBA4_rep1 has 0.00% values\n",
      "Column HPA007982_SBA4_rep1 has 31.51% values\n",
      "Column HPA028190_SBA4_rep1 has 14.32% values\n",
      "Column HPA031466_SBA4_rep1 has 0.00% values\n",
      "Column HPA040972_SBA4_rep1 has 0.00% values\n",
      "Column HPA001526_SBA4_rep1 has 8.85% values\n",
      "Column HPA002021_SBA4_rep1 has 45.57% values\n",
      "Column HPA010558_SBA4_rep1 has 0.00% values\n",
      "Column HPA013390_SBA4_rep1 has 7.03% values\n",
      "Column HPA020610_SBA4_rep1 has 0.00% values\n",
      "Column HPA028657_SBA4_rep1 has 34.64% values\n",
      "Column HPA030651_SBA4_rep1 has 0.00% values\n",
      "Column HPA000226_SBA4_rep1 has 0.00% values\n",
      "Column HPA007316_SBA4_rep1 has 10.42% values\n",
      "Column HPA008128_SBA4_rep1 has 7.55% values\n",
      "Column HPA064736_SBA4_rep1 has 49.74% values\n",
      "Column HPA041991_SBA4_rep1 has 0.00% values\n",
      "Column HPA000564_SBA4_rep1 has 0.00% values\n",
      "Column HPA007427_SBA4_rep1 has 22.14% values\n",
      "Column HPA035222_SBA4_rep1 has 0.00% values\n",
      "Column HPA041943_SBA4_rep1 has 0.00% values\n",
      "Column HPA001373_SBA4_rep1 has 31.51% values\n",
      "Column HPA001833_SBA4_rep1 has 0.00% values\n",
      "Column HPA003927_SBA4_rep1 has 0.00% values\n",
      "Column HPA006666_SBA4_rep1 has 6.51% values\n",
      "Column HPA008880_SBA4_rep1 has 26.30% values\n",
      "Column HPA015109_SBA4_rep1 has 7.03% values\n",
      "Column HPA027526_SBA4_rep1 has 38.02% values\n",
      "Column HPA035029_SBA4_rep1 has 45.57% values\n",
      "Column HPA003157_SBA4_rep1 has 13.80% values\n",
      "Column HPA011918_SBA4_rep1 has 0.00% values\n",
      "Column HPA023314_SBA4_rep1 has 0.00% values\n",
      "Column HPA015236_SBA4_rep1 has 21.61% values\n",
      "Column HPA031335_SBA4_rep1 has 0.00% values\n",
      "Column HPA031717_SBA4_rep1 has 0.00% values\n",
      "Column HPA026430_SBA4_rep1 has 7.81% values\n",
      "We have 58 proteins with less than 50% datapoints\n"
     ]
    }
   ],
   "source": [
    "# Calculate column statistics for low content columns\n",
    "value_percentage = calculate_column_value_percentage(dataset, 15)\n",
    "limit = 50\n",
    "low_percentage_columns = value_percentage[value_percentage < limit]\n",
    "\n",
    "# Visualize status\n",
    "num = 0\n",
    "for column, percentage in low_percentage_columns.items():\n",
    "    print(f\"Column {column} has {percentage:.2f}% values\")\n",
    "    num += 1\n",
    "\n",
    "print(f\"We have {num} proteins with less than {limit}% datapoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop: Index(['HPA003948_SBA1_rep1', 'HPA059806_SBA1_rep1', 'HPA055893_SBA2_rep1',\n",
      "       'HPA035933_SBA2_rep1', 'HPA009426_SBA2_rep1', 'HPA057437_SBA3_rep1',\n",
      "       'HPA003909_SBA3_rep1', 'HPA015774_SBA3_rep1', 'HPA003223_SBA3_rep1',\n",
      "       'HPA003948_SBA3_rep1', 'Empty_SBA3_rep1', 'HPA040591_SBA3_rep1',\n",
      "       'HPA034960_SBA3_rep1', 'HPA021513_SBA3_rep1', 'HPA058513_SBA3_rep1',\n",
      "       'HPA036287_SBA3_rep1', 'HPA073315_SBA3_rep1', 'HPA041863_SBA3_rep1',\n",
      "       'HPA004712_SBA3_rep1', 'HPA074922_SBA3_rep1', 'HPA000837_SBA4_rep1',\n",
      "       'HPA001482_SBA4_rep1', 'HPA000293_SBA4_rep1', 'HPA007982_SBA4_rep1',\n",
      "       'HPA028190_SBA4_rep1', 'HPA031466_SBA4_rep1', 'HPA040972_SBA4_rep1',\n",
      "       'HPA001526_SBA4_rep1', 'HPA002021_SBA4_rep1', 'HPA010558_SBA4_rep1',\n",
      "       'HPA013390_SBA4_rep1', 'HPA020610_SBA4_rep1', 'HPA028657_SBA4_rep1',\n",
      "       'HPA030651_SBA4_rep1', 'HPA000226_SBA4_rep1', 'HPA007316_SBA4_rep1',\n",
      "       'HPA008128_SBA4_rep1', 'HPA064736_SBA4_rep1', 'HPA041991_SBA4_rep1',\n",
      "       'HPA000564_SBA4_rep1', 'HPA007427_SBA4_rep1', 'HPA035222_SBA4_rep1',\n",
      "       'HPA041943_SBA4_rep1', 'HPA001373_SBA4_rep1', 'HPA001833_SBA4_rep1',\n",
      "       'HPA003927_SBA4_rep1', 'HPA006666_SBA4_rep1', 'HPA008880_SBA4_rep1',\n",
      "       'HPA015109_SBA4_rep1', 'HPA027526_SBA4_rep1', 'HPA035029_SBA4_rep1',\n",
      "       'HPA003157_SBA4_rep1', 'HPA011918_SBA4_rep1', 'HPA023314_SBA4_rep1',\n",
      "       'HPA015236_SBA4_rep1', 'HPA031335_SBA4_rep1', 'HPA031717_SBA4_rep1',\n",
      "       'HPA026430_SBA4_rep1'],\n",
      "      dtype='object')\n",
      "Before drop: (384, 1039)\n",
      "After drop: (384, 981)\n"
     ]
    }
   ],
   "source": [
    "# Remove empty columns\n",
    "columns_to_drop = low_percentage_columns.index\n",
    "print(\"Columns to drop:\", columns_to_drop)\n",
    "\n",
    "# Check changes\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "dataset.drop(labels=columns_to_drop, axis=\"columns\", inplace=True)\n",
    "print(\"After drop:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: (384, 981)\n",
      "After drop: (384, 976)\n"
     ]
    }
   ],
   "source": [
    "# Remove abundant data and calibration columns\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "dataset.drop(labels=['TREAT', 'Plate', 'Location', 'Empty_SBA1_rep1', 'Rabbit.IgG_SBA1_rep1'], axis='columns', inplace=True)\n",
    "print(\"After drop:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row Based Data Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_wrong_value_rows(df, column_name, wrong_val):\n",
    "    \"\"\"\n",
    "    Removes rows from the DataFrame where the specified column has the specified wrong value.\n",
    "\n",
    "    :param df: A pandas DataFrame from which rows will be removed.\n",
    "    :param column_name: The name of the column to check for the wrong value.\n",
    "    :param wrong_val: The value considered wrong in the specified column.\n",
    "    :return: A pandas DataFrame with rows containing the wrong value in the specified column removed.\n",
    "    \"\"\"\n",
    "    if isinstance(wrong_val, str):\n",
    "        wrong_val = list([wrong_val])\n",
    "        \n",
    "    for val in wrong_val:\n",
    "        # Find indices of rows with the wrong value\n",
    "        incorrect = dataset[column_name] == val\n",
    "        indices_to_drop = incorrect[incorrect == True].index\n",
    "        # Drop these rows\n",
    "        df.drop(indices_to_drop, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: (384, 976)\n",
      "After drop: (372, 976)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with invalid sample data\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "dataset = remove_wrong_value_rows(dataset, 'Sample_ID', ['BLANK', 'POOL 1', 'POOL 2'])\n",
    "print(\"After drop:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: (372, 976)\n",
      "After drop: (357, 976)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN in the row's key values\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "dataset.dropna(subset=['Sample_ID','Disease'], inplace=True)\n",
    "print(\"After drop:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle sample duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicate_indecies(df, columns):\n",
    "    \"\"\"\n",
    "    Find indices of rows with the wrong value in the specified column.\n",
    "    \"\"\"\n",
    "    duplicate = df.duplicated(subset=columns, keep=False)\n",
    "    duplicate_indexes = duplicate[duplicate == True].index\n",
    "    return duplicate_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_row_value_percentage(df, start_column=0):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of actual (non-NA) data points for each row in a pandas DataFrame.\n",
    "\n",
    "    :param df: A pandas DataFrame with potential NA values.\n",
    "    :return: A pandas Series with the percentage of non-NA values for each row.\n",
    "    \"\"\"\n",
    "    # Adjust for 0-based indexing\n",
    "    start_index = max(0, start_column - 1)\n",
    "\n",
    "    # Select only the columns within the specified interval\n",
    "    interval_df = df.iloc[:, start_index:]\n",
    "\n",
    "    # Calculate the number of non-NA values per row\n",
    "    value_counts_per_row = df.notna().sum(axis=1)\n",
    "\n",
    "    # Calculate the total number of columns (to handle potential NA values)\n",
    "    total_columns = interval_df.shape[1]\n",
    "\n",
    "    # Calculate the percentage of non-NA values for each row\n",
    "    value_percentage_per_row = (value_counts_per_row / total_columns) * 100\n",
    "\n",
    "    return value_percentage_per_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_rows(df, duplicate_indexes, row_val_percentages):\n",
    "\n",
    "    for i in duplicate_indexes:\n",
    "        # For each duplicate find the duplicate sample.ID value using the index\n",
    "        sample_ID = df.iloc[i]['Sample_ID']\n",
    "\n",
    "        # Find all row indicies of occurances of the value\n",
    "        duplicate_sample_ID_indicies = df.index[df['Sample_ID'] == sample_ID]\n",
    "\n",
    "        # Find which of these rows have the highest percentage in row_val_percentages\n",
    "        best_index = -1\n",
    "        best_val = -1\n",
    "        for duplicate_idx in duplicate_sample_ID_indicies:\n",
    "            val = row_val_percentages.loc[duplicate_idx]\n",
    "\n",
    "            if (val > best_val):\n",
    "                best_val = val\n",
    "                best_index = duplicate_idx\n",
    "\n",
    "        # Remove best from list of duplicates\n",
    "        duplicate_sample_ID_indicies = duplicate_sample_ID_indicies.drop(best_index)\n",
    "\n",
    "        # Drop the rest of the duplicates\n",
    "        df.drop(index=duplicate_sample_ID_indicies, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: (357, 976)\n",
      "After drop: (342, 976)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows for same Sample_ID\n",
    "duplicate_indexes = get_duplicate_indecies(dataset, 'Sample_ID')\n",
    "row_val_percentages = calculate_row_value_percentage(dataset, start_column=15)\n",
    "\n",
    "# Check changes\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "remove_duplicate_rows(dataset, duplicate_indexes, row_val_percentages)\n",
    "print(\"After drop:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Row handling based on FT5 (Should consider data generation based on age/other tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: (342, 976)\n",
      "After drop: (301, 976)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Age</th>\n",
       "      <th>FT1</th>\n",
       "      <th>FT2</th>\n",
       "      <th>FT3</th>\n",
       "      <th>FT4</th>\n",
       "      <th>...</th>\n",
       "      <th>HPA049320_SBA4_rep1</th>\n",
       "      <th>HPA051620_SBA4_rep1</th>\n",
       "      <th>HPA054862_SBA4_rep1</th>\n",
       "      <th>HPA003901_SBA4_rep1</th>\n",
       "      <th>HPA035863_SBA4_rep1</th>\n",
       "      <th>HPA040052_SBA4_rep1</th>\n",
       "      <th>HPA041542_SBA4_rep1</th>\n",
       "      <th>HPA044582_SBA4_rep1</th>\n",
       "      <th>HPA045702_SBA4_rep1</th>\n",
       "      <th>HPA048982_SBA4_rep1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>S237</td>\n",
       "      <td>P5</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.72</td>\n",
       "      <td>2.538071</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>488.7</td>\n",
       "      <td>...</td>\n",
       "      <td>12.543301</td>\n",
       "      <td>12.608368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.598509</td>\n",
       "      <td>12.452527</td>\n",
       "      <td>12.495444</td>\n",
       "      <td>12.800951</td>\n",
       "      <td>12.696679</td>\n",
       "      <td>12.602999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>S220</td>\n",
       "      <td>P5</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.41</td>\n",
       "      <td>2.531646</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>0.275482</td>\n",
       "      <td>475.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.390816</td>\n",
       "      <td>12.571472</td>\n",
       "      <td>12.389882</td>\n",
       "      <td>12.490296</td>\n",
       "      <td>12.522449</td>\n",
       "      <td>12.519723</td>\n",
       "      <td>12.413517</td>\n",
       "      <td>12.917533</td>\n",
       "      <td>12.514924</td>\n",
       "      <td>12.618601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>S91</td>\n",
       "      <td>P6</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.76</td>\n",
       "      <td>2.237136</td>\n",
       "      <td>0.346021</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>449.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.464468</td>\n",
       "      <td>12.599863</td>\n",
       "      <td>12.459217</td>\n",
       "      <td>12.509688</td>\n",
       "      <td>12.482434</td>\n",
       "      <td>12.507582</td>\n",
       "      <td>12.593243</td>\n",
       "      <td>12.733109</td>\n",
       "      <td>12.554774</td>\n",
       "      <td>12.587261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>S49</td>\n",
       "      <td>P134</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.560804</td>\n",
       "      <td>12.531565</td>\n",
       "      <td>12.490397</td>\n",
       "      <td>12.419143</td>\n",
       "      <td>12.585085</td>\n",
       "      <td>12.509866</td>\n",
       "      <td>12.386933</td>\n",
       "      <td>12.820761</td>\n",
       "      <td>12.532538</td>\n",
       "      <td>12.661084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>S79</td>\n",
       "      <td>P134</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.583934</td>\n",
       "      <td>12.599499</td>\n",
       "      <td>12.527210</td>\n",
       "      <td>12.636333</td>\n",
       "      <td>12.440678</td>\n",
       "      <td>12.555278</td>\n",
       "      <td>12.617759</td>\n",
       "      <td>12.909895</td>\n",
       "      <td>12.578293</td>\n",
       "      <td>12.685735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>S70</td>\n",
       "      <td>P135</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.456166</td>\n",
       "      <td>12.597872</td>\n",
       "      <td>12.496037</td>\n",
       "      <td>12.652614</td>\n",
       "      <td>12.457952</td>\n",
       "      <td>12.487103</td>\n",
       "      <td>12.521334</td>\n",
       "      <td>12.823034</td>\n",
       "      <td>12.541253</td>\n",
       "      <td>12.606741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>S2</td>\n",
       "      <td>P135</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.481201</td>\n",
       "      <td>12.621694</td>\n",
       "      <td>12.415145</td>\n",
       "      <td>12.616261</td>\n",
       "      <td>12.450933</td>\n",
       "      <td>12.536485</td>\n",
       "      <td>12.559103</td>\n",
       "      <td>12.795596</td>\n",
       "      <td>12.552749</td>\n",
       "      <td>12.618074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>S83</td>\n",
       "      <td>P136</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.403677</td>\n",
       "      <td>12.545281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.439043</td>\n",
       "      <td>12.489224</td>\n",
       "      <td>12.565305</td>\n",
       "      <td>12.600430</td>\n",
       "      <td>12.764371</td>\n",
       "      <td>12.561835</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>S41</td>\n",
       "      <td>P136</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.391321</td>\n",
       "      <td>12.450349</td>\n",
       "      <td>12.378164</td>\n",
       "      <td>12.358069</td>\n",
       "      <td>12.510605</td>\n",
       "      <td>12.474641</td>\n",
       "      <td>12.471794</td>\n",
       "      <td>12.904288</td>\n",
       "      <td>12.526909</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>S276</td>\n",
       "      <td>P7</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.90</td>\n",
       "      <td>1.461988</td>\n",
       "      <td>0.155763</td>\n",
       "      <td>0.114155</td>\n",
       "      <td>317.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.476450</td>\n",
       "      <td>12.425208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.397139</td>\n",
       "      <td>12.523445</td>\n",
       "      <td>12.530703</td>\n",
       "      <td>12.503940</td>\n",
       "      <td>12.791145</td>\n",
       "      <td>12.471993</td>\n",
       "      <td>12.604703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>S302</td>\n",
       "      <td>P7</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.94</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.117233</td>\n",
       "      <td>0.093284</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.397159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>S351</td>\n",
       "      <td>P7</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.67</td>\n",
       "      <td>0.923361</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.070972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.476410</td>\n",
       "      <td>12.483707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.294553</td>\n",
       "      <td>12.562372</td>\n",
       "      <td>12.481790</td>\n",
       "      <td>12.456831</td>\n",
       "      <td>13.131979</td>\n",
       "      <td>12.578485</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>S348</td>\n",
       "      <td>P9</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.428524</td>\n",
       "      <td>12.626223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.414213</td>\n",
       "      <td>12.507686</td>\n",
       "      <td>12.588375</td>\n",
       "      <td>12.506773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.445122</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>S286</td>\n",
       "      <td>P9</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.03</td>\n",
       "      <td>1.020408</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.380450</td>\n",
       "      <td>12.483917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.590108</td>\n",
       "      <td>12.615858</td>\n",
       "      <td>12.488005</td>\n",
       "      <td>12.546289</td>\n",
       "      <td>12.861138</td>\n",
       "      <td>12.520447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>S273</td>\n",
       "      <td>P10</td>\n",
       "      <td>DNHS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.58</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>209.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.488839</td>\n",
       "      <td>12.597753</td>\n",
       "      <td>12.562960</td>\n",
       "      <td>12.415403</td>\n",
       "      <td>12.642297</td>\n",
       "      <td>12.629846</td>\n",
       "      <td>12.642667</td>\n",
       "      <td>13.134355</td>\n",
       "      <td>12.628539</td>\n",
       "      <td>12.773149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 976 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Sample_ID Participant_ID Dataset  Disease    Age       FT1       FT2  \\\n",
       "5    6      S237             P5    DNHS      1.0  11.72  2.538071  0.628931   \n",
       "6    7      S220             P5    DNHS      1.0  13.41  2.531646  0.492611   \n",
       "8    9       S91             P6    DNHS      1.0  11.76  2.237136  0.346021   \n",
       "9   10       S49           P134    DNHS      0.0    NaN       NaN       NaN   \n",
       "16  17       S79           P134    DNHS      0.0    NaN       NaN       NaN   \n",
       "18  19       S70           P135    DNHS      0.0    NaN       NaN       NaN   \n",
       "21  22        S2           P135    DNHS      0.0    NaN       NaN       NaN   \n",
       "26  27       S83           P136    DNHS      0.0    NaN       NaN       NaN   \n",
       "27  28       S41           P136    DNHS      0.0    NaN       NaN       NaN   \n",
       "31  32      S276             P7    DNHS      1.0  10.90  1.461988  0.155763   \n",
       "32  33      S302             P7    DNHS      1.0  11.94  0.995025  0.117233   \n",
       "33  34      S351             P7    DNHS      1.0  12.67  0.923361  0.092764   \n",
       "35  36      S348             P9    DNHS      1.0  11.12       NaN  0.196078   \n",
       "36  37      S286             P9    DNHS      1.0  12.03  1.020408  0.112360   \n",
       "38  39      S273            P10    DNHS      1.0  11.58  0.869565       NaN   \n",
       "\n",
       "         FT3    FT4  ...  HPA049320_SBA4_rep1  HPA051620_SBA4_rep1  \\\n",
       "5   0.367647  488.7  ...            12.543301            12.608368   \n",
       "6   0.275482  475.0  ...            12.390816            12.571472   \n",
       "8   0.176991  449.0  ...            12.464468            12.599863   \n",
       "9        NaN    NaN  ...            12.560804            12.531565   \n",
       "16       NaN    NaN  ...            12.583934            12.599499   \n",
       "18       NaN    NaN  ...            12.456166            12.597872   \n",
       "21       NaN    NaN  ...            12.481201            12.621694   \n",
       "26       NaN    NaN  ...            12.403677            12.545281   \n",
       "27       NaN    NaN  ...            12.391321            12.450349   \n",
       "31  0.114155  317.0  ...            12.476450            12.425208   \n",
       "32  0.093284  150.0  ...                  NaN                  NaN   \n",
       "33  0.070972    NaN  ...            12.476410            12.483707   \n",
       "35       NaN    NaN  ...            12.428524            12.626223   \n",
       "36       NaN   75.0  ...            12.380450            12.483917   \n",
       "38  0.000000  209.0  ...            12.488839            12.597753   \n",
       "\n",
       "    HPA054862_SBA4_rep1  HPA003901_SBA4_rep1  HPA035863_SBA4_rep1  \\\n",
       "5                   NaN                  NaN            12.598509   \n",
       "6             12.389882            12.490296            12.522449   \n",
       "8             12.459217            12.509688            12.482434   \n",
       "9             12.490397            12.419143            12.585085   \n",
       "16            12.527210            12.636333            12.440678   \n",
       "18            12.496037            12.652614            12.457952   \n",
       "21            12.415145            12.616261            12.450933   \n",
       "26                  NaN            12.439043            12.489224   \n",
       "27            12.378164            12.358069            12.510605   \n",
       "31                  NaN            12.397139            12.523445   \n",
       "32                  NaN                  NaN            12.397159   \n",
       "33                  NaN            12.294553            12.562372   \n",
       "35                  NaN            12.414213            12.507686   \n",
       "36                  NaN            12.590108            12.615858   \n",
       "38            12.562960            12.415403            12.642297   \n",
       "\n",
       "    HPA040052_SBA4_rep1  HPA041542_SBA4_rep1  HPA044582_SBA4_rep1  \\\n",
       "5             12.452527            12.495444            12.800951   \n",
       "6             12.519723            12.413517            12.917533   \n",
       "8             12.507582            12.593243            12.733109   \n",
       "9             12.509866            12.386933            12.820761   \n",
       "16            12.555278            12.617759            12.909895   \n",
       "18            12.487103            12.521334            12.823034   \n",
       "21            12.536485            12.559103            12.795596   \n",
       "26            12.565305            12.600430            12.764371   \n",
       "27            12.474641            12.471794            12.904288   \n",
       "31            12.530703            12.503940            12.791145   \n",
       "32                  NaN                  NaN                  NaN   \n",
       "33            12.481790            12.456831            13.131979   \n",
       "35            12.588375            12.506773                  NaN   \n",
       "36            12.488005            12.546289            12.861138   \n",
       "38            12.629846            12.642667            13.134355   \n",
       "\n",
       "    HPA045702_SBA4_rep1  HPA048982_SBA4_rep1  \n",
       "5             12.696679            12.602999  \n",
       "6             12.514924            12.618601  \n",
       "8             12.554774            12.587261  \n",
       "9             12.532538            12.661084  \n",
       "16            12.578293            12.685735  \n",
       "18            12.541253            12.606741  \n",
       "21            12.552749            12.618074  \n",
       "26            12.561835                  NaN  \n",
       "27            12.526909                  NaN  \n",
       "31            12.471993            12.604703  \n",
       "32                  NaN                  NaN  \n",
       "33            12.578485                  NaN  \n",
       "35            12.445122                  NaN  \n",
       "36            12.520447                  NaN  \n",
       "38            12.628539            12.773149  \n",
       "\n",
       "[15 rows x 976 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with NaN values in the FT5 column\n",
    "not_na = dataset['FT5'].notna()\n",
    "indices_to_drop = not_na[not_na == False].index\n",
    "\n",
    "# Check changes\n",
    "print(\"Before drop:\", dataset.shape)\n",
    "dataset.drop(indices_to_drop, inplace=True)\n",
    "print(\"After drop:\", dataset.shape)\n",
    "\n",
    "dataset.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Northstar Prediction Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle Missing Values:\n",
    "Before feature selection, ensure all NaN values are handled appropriately, either by imputation or by removing rows/columns with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Isolate relevant data\n",
    "df = dataset.iloc[:, 10:] \n",
    "\n",
    "# Option 1: Impute missing values (e.g., with the mean of each column)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Option 2: Drop rows with any NaN values (use with caution)\n",
    "# df_dropped = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df_imputed['FT5'] # Vector for the target variable\n",
    "X = df_imputed.iloc[:, 1:] # Matrix with variable input\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Univariate Feature Selection\n",
    "This method selects the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features Shape: (240, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Select the top 100 features based on ANOVA F-value\n",
    "select_k_best = SelectKBest(f_classif, k=100)\n",
    "X_train_selected = select_k_best.fit_transform(X_train, y_train)\n",
    "X_test_selected = select_k_best.transform(X_test)\n",
    "\n",
    "print(\"Selected Features Shape:\", X_train_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Selection Using Model\n",
    "You can use a model to determine the importance of each feature and select the most important features accordingly. Here, we'll use ExtraTreesClassifier as an example for classification. For regression tasks, you could use ExtraTreesRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Selected Features Shape: (240, 444)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=50)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "# Model-based feature selection\n",
    "model_select = SelectFromModel(model, prefit=True)\n",
    "X_train_model = model_select.transform(X_train)\n",
    "X_test_model = model_select.transform(X_test)\n",
    "\n",
    "print(\"Model Selected Features Shape:\", X_train_model.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recursive Feature Elimination (RFE)\n",
    "RFE works by recursively removing the least important feature and building a model on those features that remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize RFE and select the top 100 features\u001b[39;00m\n\u001b[0;32m      8\u001b[0m rfe \u001b[38;5;241m=\u001b[39m RFE(estimator\u001b[38;5;241m=\u001b[39mmodel, n_features_to_select\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m X_train_rfe \u001b[38;5;241m=\u001b[39m \u001b[43mrfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m X_test_rfe \u001b[38;5;241m=\u001b[39m rfe\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRFE Selected Features Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train_rfe\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    279\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1064\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1063\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:258\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    257\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:305\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[1;32m--> 305\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    308\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    309\u001b[0m     estimator,\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[0;32m    311\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    312\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1296\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1321\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:455\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    451\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (C \u001b[38;5;241m*\u001b[39m sw_sum)\n\u001b[0;32m    452\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    453\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    454\u001b[0m ]\n\u001b[1;32m--> 455\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    470\u001b[0m     solver,\n\u001b[0;32m    471\u001b[0m     opt_res,\n\u001b[0;32m    472\u001b[0m     max_iter,\n\u001b[0;32m    473\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    475\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:369\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    363\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    372\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:294\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_and_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\numpy\\core\\numeric.py:2439\u001b[0m, in \u001b[0;36marray_equal\u001b[1;34m(a1, a2, equal_nan)\u001b[0m\n\u001b[0;32m   2437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m equal_nan:\n\u001b[1;32m-> 2439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mall())\n\u001b[0;32m   2440\u001b[0m \u001b[38;5;66;03m# Handling NaN values if equal_nan is True\u001b[39;00m\n\u001b[0;32m   2441\u001b[0m a1nan, a2nan \u001b[38;5;241m=\u001b[39m isnan(a1), isnan(a2)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model to be used\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Initialize RFE and select the top 100 features\n",
    "rfe = RFE(estimator=model, n_features_to_select=100, step=1)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "print(\"RFE Selected Features Shape:\", X_train_rfe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "QP-jazpobWuT",
    "outputId": "c600c891-f03a-40dd-dc42-9b5fe8828e60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-166-0d865e1640cf>:2: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  max = dataset.max(axis=None)\n",
      "<ipython-input-166-0d865e1640cf>:2: FutureWarning: The default value of numeric_only in DataFrame.max is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  max = dataset.max(axis=None)\n",
      "<ipython-input-166-0d865e1640cf>:3: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  min = dataset.min(axis=None)\n",
      "<ipython-input-166-0d865e1640cf>:3: FutureWarning: The default value of numeric_only in DataFrame.min is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  min = dataset.min(axis=None)\n",
      "<ipython-input-166-0d865e1640cf>:4: FutureWarning: In a future version, DataFrame.median(axis=None) will return a scalar median over the entire DataFrame. To retain the old behavior, use 'frame.median(axis=0)' or just 'frame.median()'\n",
      "  median = dataset.median(axis=None)\n",
      "<ipython-input-166-0d865e1640cf>:4: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  median = dataset.median(axis=None)\n"
     ]
    }
   ],
   "source": [
    "# Get summary statistics for whole data set\n",
    "max = dataset.max(axis=None)\n",
    "min = dataset.min(axis=None)\n",
    "median = dataset.median(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "3NOPw1kbfr3d",
    "outputId": "01955389-03ac-4ae4-e8b3-98924b0dce11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                           384\n",
      "Disease                      1.0\n",
      "serum.age                   16.3\n",
      "FT1                     3.215434\n",
      "FT2                     0.628931\n",
      "                         ...    \n",
      "HPA040052_SBA4_rep1    12.907514\n",
      "HPA041542_SBA4_rep1    12.814063\n",
      "HPA044582_SBA4_rep1    13.232916\n",
      "HPA045702_SBA4_rep1    12.836329\n",
      "HPA048982_SBA4_rep1    12.919319\n",
      "Length: 1035, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "EeXcB6GFE30h",
    "outputId": "efd87f3f-6b66-45dc-e5e7-3269582a7c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                             1\n",
      "Disease                      0.0\n",
      "serum.age               4.016427\n",
      "FT1                          0.0\n",
      "FT2                          0.0\n",
      "                         ...    \n",
      "HPA040052_SBA4_rep1    11.823214\n",
      "HPA041542_SBA4_rep1    12.013636\n",
      "HPA044582_SBA4_rep1    12.580456\n",
      "HPA045702_SBA4_rep1    12.267231\n",
      "HPA048982_SBA4_rep1     11.92033\n",
      "Length: 1035, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "LiItUIv2E397",
    "outputId": "e5382aab-b6b3-4441-b103-b58460919818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                     192.500000\n",
      "Disease                  1.000000\n",
      "serum.age                7.585216\n",
      "FT1                      0.458295\n",
      "FT2                      0.244801\n",
      "                          ...    \n",
      "HPA040052_SBA4_rep1     12.543317\n",
      "HPA041542_SBA4_rep1     12.559998\n",
      "HPA044582_SBA4_rep1     12.803850\n",
      "HPA045702_SBA4_rep1     12.530788\n",
      "HPA048982_SBA4_rep1     12.640344\n",
      "Length: 1034, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "12FnOCJjFAQ1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1710344581051,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "ipCmokfYJ2jb",
    "outputId": "a5dc0b64-f81a-4726-e46d-70f75a598129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global maximum intensity: 18.665777617921\n",
      "Global median intensity: 12.325486692708193\n",
      "Global minimum intensity: 8.72125121808696\n"
     ]
    }
   ],
   "source": [
    "# Get protein intensitiy values only by removing first 15 columns\n",
    "intensities = dataset.iloc[:, 14:]\n",
    "# print(intensities)\n",
    "\n",
    "# Calculate min, max, and median for intensities\n",
    "min_values = intensities.min()\n",
    "max_values = intensities.max()\n",
    "median_values = intensities.median()\n",
    "\n",
    "# Now, calculate the average of these statistics across the columns\n",
    "global_min = min_values.min()\n",
    "global_max = max_values.max()\n",
    "global_median = median_values.mean()\n",
    "\n",
    "print(\"Global maximum intensity:\", global_max)\n",
    "print(\"Global median intensity:\", global_median)\n",
    "print(\"Global minimum intensity:\", global_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1710344581052,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "oCNK1_JeKt06",
    "outputId": "0284d031-559c-4e50-f024-ca01909775db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID Sample.ID Participant.ID dataset  Disease  serum.age TREAT  FT1  FT2  \\\n",
      "0   1       S87             P3    DNHS      1.0   11.60849   NaN  0.0  0.0   \n",
      "1   2       S10             P3    DNHS      1.0   12.62423   NaN  NaN  NaN   \n",
      "2   3       S19             P3    DNHS      1.0   13.62081   NaN  NaN  NaN   \n",
      "3   4      S137             P4    DNHS      1.0   11.42505   NaN  NaN  NaN   \n",
      "4   5      S182             P4    DNHS      1.0   13.24572   NaN  NaN  NaN   \n",
      "\n",
      "   FT3  ...  HPA049320_SBA4_rep1  HPA051620_SBA4_rep1  HPA054862_SBA4_rep1  \\\n",
      "0  NaN  ...            12.476497            12.666707            12.331400   \n",
      "1  NaN  ...            12.494297            12.564169            12.354718   \n",
      "2  NaN  ...            12.554581            12.707240            12.460004   \n",
      "3  NaN  ...            12.455811            12.505603            12.416459   \n",
      "4  NaN  ...            12.523768            12.598164            12.369592   \n",
      "\n",
      "  HPA003901_SBA4_rep1  HPA035863_SBA4_rep1  HPA040052_SBA4_rep1  \\\n",
      "0           12.410101            12.504796            12.580695   \n",
      "1           12.581718            12.441237            12.583769   \n",
      "2           12.610387            12.504661            12.556319   \n",
      "3           12.510771            12.472934            12.556096   \n",
      "4           12.605211            12.523768            12.503911   \n",
      "\n",
      "   HPA041542_SBA4_rep1  HPA044582_SBA4_rep1  HPA045702_SBA4_rep1  \\\n",
      "0            12.574592            12.797013            12.492433   \n",
      "1            12.579893            12.660894            12.450384   \n",
      "2            12.679701            12.824755            12.517335   \n",
      "3            12.473760            12.744020            12.511776   \n",
      "4            12.557672            12.926602            12.518327   \n",
      "\n",
      "   HPA048982_SBA4_rep1  \n",
      "0            12.622226  \n",
      "1            12.704464  \n",
      "2            12.836970  \n",
      "3            12.666065  \n",
      "4            12.668579  \n",
      "\n",
      "[5 rows x 1039 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalize protein intensities in dataset\n",
    "\"\"\"\n",
    " OBS: we do not want to do this initially\n",
    "      also it might make the  model less useful\n",
    "      since it makes intensities from other\n",
    "      studies or clinical samples harder to\n",
    "      compare.\n",
    "\n",
    "      Also, we are normalizing the intensities globally instead of per-column\n",
    "      (per-protein). Would doing it per protein be better?\n",
    "\n",
    "      Disabled for now.\n",
    "\"\"\"\n",
    "# dataset.iloc[:, 14:] = (dataset.iloc[:, 14:] - global_min) / (global_max - global_min)\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1710344581052,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "lXDPhBhkMelA",
    "outputId": "bfebf9ce-4413-4217-edef-a724b13670f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FT1', 'FT2', 'FT3', 'FT4', 'FT5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop physical tests (might include them in the future)\n",
    "columns_to_drop = dataset.columns[7:12]\n",
    "dataset = dataset.drop(columns=columns_to_drop)\n",
    "\n",
    "print(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1710344581052,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "omE-rJqLPIgB",
    "outputId": "3459a43a-f3a1-4329-ebb2-f1f910bd9cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID Sample.ID Participant.ID dataset  Disease  serum.age TREAT  Plate  \\\n",
      "0   1       S87             P3    DNHS      1.0   11.60849   NaN      1   \n",
      "1   2       S10             P3    DNHS      1.0   12.62423   NaN      1   \n",
      "2   3       S19             P3    DNHS      1.0   13.62081   NaN      1   \n",
      "3   4      S137             P4    DNHS      1.0   11.42505   NaN      2   \n",
      "4   5      S182             P4    DNHS      1.0   13.24572   NaN      2   \n",
      "\n",
      "  Location  HPA029198_SBA1_rep1  ...  HPA049320_SBA4_rep1  \\\n",
      "0      D12            12.264364  ...            12.476497   \n",
      "1       C2            12.264976  ...            12.494297   \n",
      "2       D3            12.278605  ...            12.554581   \n",
      "3       H6            12.351390  ...            12.455811   \n",
      "4      H12            12.301256  ...            12.523768   \n",
      "\n",
      "   HPA051620_SBA4_rep1  HPA054862_SBA4_rep1  HPA003901_SBA4_rep1  \\\n",
      "0            12.666707            12.331400            12.410101   \n",
      "1            12.564169            12.354718            12.581718   \n",
      "2            12.707240            12.460004            12.610387   \n",
      "3            12.505603            12.416459            12.510771   \n",
      "4            12.598164            12.369592            12.605211   \n",
      "\n",
      "   HPA035863_SBA4_rep1  HPA040052_SBA4_rep1  HPA041542_SBA4_rep1  \\\n",
      "0            12.504796            12.580695            12.574592   \n",
      "1            12.441237            12.583769            12.579893   \n",
      "2            12.504661            12.556319            12.679701   \n",
      "3            12.472934            12.556096            12.473760   \n",
      "4            12.523768            12.503911            12.557672   \n",
      "\n",
      "   HPA044582_SBA4_rep1  HPA045702_SBA4_rep1  HPA048982_SBA4_rep1  \n",
      "0            12.797013            12.492433            12.622226  \n",
      "1            12.660894            12.450384            12.704464  \n",
      "2            12.824755            12.517335            12.836970  \n",
      "3            12.744020            12.511776            12.666065  \n",
      "4            12.926602            12.518327            12.668579  \n",
      "\n",
      "[5 rows x 1034 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print final dataset\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1710344581052,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "Bof-xPCuyVkW",
    "outputId": "df017fb6-8373-44b6-c237-704bd1430bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   serum.age  HPA029198_SBA1_rep1  HPA047839_SBA1_rep1  HPA029005_SBA1_rep1  \\\n",
      "0   11.60849            12.264364            12.159417            12.348176   \n",
      "1   12.62423            12.264976            12.226864            12.430424   \n",
      "2   13.62081            12.278605            12.124720            12.377718   \n",
      "3   11.42505            12.351390            12.227065            12.320271   \n",
      "4   13.24572            12.301256            12.260200            12.403662   \n",
      "\n",
      "   HPA049793_SBA1_rep1  HPA014245_SBA1_rep1  HPA053793_SBA1_rep1  \\\n",
      "0            12.906300            12.211722            12.322140   \n",
      "1            13.152528            12.245174            12.340043   \n",
      "2            13.055278            12.206496            12.354011   \n",
      "3            12.655442            12.267009            12.340713   \n",
      "4            13.016106            12.140189            12.333273   \n",
      "\n",
      "   HPA059859_SBA1_rep1  HPA038097_SBA1_rep1  HPA061383_SBA1_rep1  ...  \\\n",
      "0            12.605700            12.446275            12.310066  ...   \n",
      "1            12.520733            12.510600            12.261979  ...   \n",
      "2            12.558732            12.542303            12.278218  ...   \n",
      "3            12.408411            12.428379            12.286022  ...   \n",
      "4            12.518398            12.617718            12.249096  ...   \n",
      "\n",
      "   HPA049320_SBA4_rep1  HPA051620_SBA4_rep1  HPA054862_SBA4_rep1  \\\n",
      "0            12.476497            12.666707            12.331400   \n",
      "1            12.494297            12.564169            12.354718   \n",
      "2            12.554581            12.707240            12.460004   \n",
      "3            12.455811            12.505603            12.416459   \n",
      "4            12.523768            12.598164            12.369592   \n",
      "\n",
      "   HPA003901_SBA4_rep1  HPA035863_SBA4_rep1  HPA040052_SBA4_rep1  \\\n",
      "0            12.410101            12.504796            12.580695   \n",
      "1            12.581718            12.441237            12.583769   \n",
      "2            12.610387            12.504661            12.556319   \n",
      "3            12.510771            12.472934            12.556096   \n",
      "4            12.605211            12.523768            12.503911   \n",
      "\n",
      "   HPA041542_SBA4_rep1  HPA044582_SBA4_rep1  HPA045702_SBA4_rep1  \\\n",
      "0            12.574592            12.797013            12.492433   \n",
      "1            12.579893            12.660894            12.450384   \n",
      "2            12.679701            12.824755            12.517335   \n",
      "3            12.473760            12.744020            12.511776   \n",
      "4            12.557672            12.926602            12.518327   \n",
      "\n",
      "   HPA048982_SBA4_rep1  \n",
      "0            12.622226  \n",
      "1            12.704464  \n",
      "2            12.836970  \n",
      "3            12.666065  \n",
      "4            12.668579  \n",
      "\n",
      "[5 rows x 1026 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create list of training vectors consisting of age and protein intensities\n",
    "\n",
    "columns = dataset.columns\n",
    "# print(columns)\n",
    "\n",
    "# Select specific columns (in this case only 5) and then from 9 through the last column\n",
    "dataset_ANN_vectors = dataset.iloc[:, [5] + list(range(9, dataset.shape[1]))]\n",
    "\n",
    "print(dataset_ANN_vectors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1710344581052,
     "user": {
      "displayName": "jnxmaster",
      "userId": "16130325099071186302"
     },
     "user_tz": -60
    },
    "id": "WLS_cxMLgJqO"
   },
   "outputs": [],
   "source": [
    "# np.loadtxt(dataset, delimiter=\",\", skiprows=0)\n",
    "\n",
    "# r = np.genfromtxt(dataset, delimiter=',', names=True, case_sensitive=True)\n",
    "# print(repr(r))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
