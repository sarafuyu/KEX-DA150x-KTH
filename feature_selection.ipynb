{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "df_imputed = pd.read_csv('imputed_data.csv')\n",
    "df_imputed.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df_imputed['FT5'] # Vector for the target variable\n",
    "X = df_imputed.iloc[:, 1:] # Matrix with variable input\n",
    "\n",
    "# Splitting the dataset into training and testing sets (80% - 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Univariate Feature Selection\n",
    "This method selects the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Select the top 100 features based on ANOVA F-value\n",
    "select_k_best = SelectKBest(f_classif, k=100)\n",
    "X_train_selected = select_k_best.fit_transform(X_train, y_train)\n",
    "X_test_selected = select_k_best.transform(X_test)\n",
    "\n",
    "print(\"Selected Features Shape:\", X_train_selected.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Selection Using Model\n",
    "You can use a model to determine the importance of each feature and select the most important features accordingly. Here, we'll use ExtraTreesClassifier as an example for classification. For regression tasks, you could use ExtraTreesRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=50)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "# Model-based feature selection\n",
    "model_select = SelectFromModel(model, prefit=True)\n",
    "X_train_model = model_select.transform(X_train)\n",
    "X_test_model = model_select.transform(X_test)\n",
    "\n",
    "print(\"Model Selected Features Shape:\", X_train_model.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recursive Feature Elimination (RFE)\n",
    "RFE works by recursively removing the least important feature and building a model on those features that remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model to be used\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Initialize RFE and select the top 100 features\n",
    "rfe = RFE(estimator=model, n_features_to_select=100, step=1)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "print(\"RFE Selected Features Shape:\", X_train_rfe.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Select the top 100 features based on ANOVA F-value\n",
    "select_k_best = SelectKBest(f_classif, k=100)\n",
    "X_train_selected = select_k_best.fit_transform(X_train, y_train)\n",
    "X_test_selected = select_k_best.transform(X_test)\n",
    "\n",
    "print(\"Selected Features Shape:\", X_train_selected.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=50)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "# Model-based feature selection\n",
    "model_select = SelectFromModel(model, prefit=True)\n",
    "X_train_model = model_select.transform(X_train)\n",
    "X_test_model = model_select.transform(X_test)\n",
    "\n",
    "print(\"Model Selected Features Shape:\", X_train_model.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model to be used\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Initialize RFE and select the top 100 features\n",
    "rfe = RFE(estimator=model, n_features_to_select=100, step=1)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "print(\"RFE Selected Features Shape:\", X_train_rfe.shape)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
